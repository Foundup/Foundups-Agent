#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
# === UTF-8 ENFORCEMENT (WSP 90) ===
# Prevent UnicodeEncodeError on Windows systems
if sys.platform.startswith('win'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
# === END UTF-8 ENFORCEMENT ===

DAE Cube Organizer - HoloIndex DAE Rampup Server

Provides immediate DAE context and structure understanding for 0102 agents.
Acts as the foundational intelligence layer that all modules plug into,
forming DAE Cubes that connect in main.py.

WSP Compliance: WSP 80 (Cube-Level DAE Orchestration), WSP 87 (Code Navigation)
"""

from __future__ import annotations

import json
import logging
import re
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class DAECube:
    """Represents a complete DAE Cube structure."""
    name: str
    description: str
    orchestrator: str
    modules: List[str] = field(default_factory=list)
    responsibilities: List[str] = field(default_factory=list)
    health_status: str = "unknown"
    last_active: Optional[str] = None
    main_py_reference: str = ""


@dataclass
class DAEModule:
    """Represents a module within a DAE cube."""
    name: str
    path: str
    domain: str
    description: str
    dependencies: List[str] = field(default_factory=list)
    health_score: int = 0


class DAECubeCodeMap:
    """
    DAE Cube Code Map - Real-time 0102 Work Context Mapping

    Creates dynamic code maps showing exactly what 0102 agents are working on,
    down to the module and line number. Integrates with IDE state, file changes,
    and agent activity to provide live navigation assistance.

    Research Inspiration:
    - Live Programming Environments (Smalltalk, Lisp machines)
    - IDE debuggers with call stack visualization
    - Code comprehension tools (CodeQL, Sourcegraph)
    """

    def __init__(self):
        self.active_contexts = {}  # agent_id -> WorkContext
        self.file_watchers = {}    # file_path -> modification_time
        self.cursor_positions = {} # agent_id -> (file, line, column)
        self.task_patterns = self._load_task_patterns()

    def _load_task_patterns(self) -> Dict[str, Dict]:
        """Load patterns for recognizing different types of development tasks."""
        return {
            'integration': {
                'keywords': ['connect', 'integrate', 'bridge', 'link', 'combine'],
                'file_patterns': ['*integration*', '*orchestrator*', '*coordinator*'],
                'confidence': 0.8
            },
            'optimization': {
                'keywords': ['optimize', 'performance', 'speed', 'efficiency', 'throttle'],
                'file_patterns': ['*throttle*', '*performance*', '*cache*'],
                'confidence': 0.7
            },
            'enhancement': {
                'keywords': ['enhance', 'improve', 'extend', 'feature', 'capability'],
                'file_patterns': ['*advisor*', '*intelligence*', '*daemon*'],
                'confidence': 0.6
            },
            'bug_fix': {
                'keywords': ['fix', 'bug', 'error', 'issue', 'problem'],
                'file_patterns': ['*test*', '*fix*', '*patch*'],
                'confidence': 0.9
            }
        }

    def update_cursor_position(self, agent_id: str, file_path: str, line: int, column: int = 0):
        """Update the current cursor position for an agent."""
        self.cursor_positions[agent_id] = (file_path, line, column)
        self._update_work_context(agent_id)

    def detect_current_task(self, agent_id: str, recent_queries: List[str] = None,
                           recent_files: List[str] = None) -> Dict[str, Any]:
        """
        Detect what task an agent is currently working on using multiple signals.

        Signals analyzed:
        1. Recent search queries (what they're asking about)
        2. Files they're editing (what they're changing)
        3. Cursor position (what they're looking at)
        4. Code patterns (what type of work)
        """
        task_info = {
            'task_type': 'unknown',
            'description': 'Unknown task',
            'active_module': 'unknown',
            'exact_location': 'unknown',
            'related_modules': [],
            'confidence': 0.0,
            'evidence': []
        }

        # Signal 1: Analyze recent queries
        if recent_queries:
            for query in recent_queries[-3:]:  # Last 3 queries
                query_lower = query.lower()
                for task_type, pattern in self.task_patterns.items():
                    if any(kw in query_lower for kw in pattern['keywords']):
                        task_info['task_type'] = task_type
                        task_info['confidence'] = max(task_info['confidence'], pattern['confidence'])
                        task_info['evidence'].append(f"Query: '{query}' matches {task_type} pattern")
                        break

        # Signal 2: Analyze files being edited
        if recent_files:
            active_module = self._extract_module_from_files(recent_files)
            if active_module:
                task_info['active_module'] = active_module
                task_info['evidence'].append(f"Active in module: {active_module}")

        # Signal 3: Cursor position analysis
        if agent_id in self.cursor_positions:
            file_path, line, column = self.cursor_positions[agent_id]
            task_info['exact_location'] = f"{file_path}:{line}"
            task_info['evidence'].append(f"Cursor at {file_path}:{line}")

            # Analyze code around cursor for task hints
            cursor_task = self._analyze_code_at_cursor(file_path, line)
            if cursor_task:
                task_info.update(cursor_task)
                task_info['evidence'].append(f"Code analysis: {cursor_task.get('description', 'Unknown')}")

        # Generate human-readable description
        task_info['description'] = self._generate_task_description(task_info)

        return task_info

    def _extract_module_from_files(self, file_paths: List[str]) -> str:
        """Extract the primary module being worked on from file paths."""
        if not file_paths:
            return 'unknown'

        # Count module occurrences
        module_counts = {}
        for path in file_paths:
            module = self._extract_module_name(path)
            module_counts[module] = module_counts.get(module, 0) + 1

        # Return most frequent module
        if module_counts:
            return max(module_counts, key=module_counts.get)

        return 'unknown'

    def _extract_module_name(self, path: str) -> str:
        """Extract module name from file path."""
        parts = path.split('/')
        if 'modules' in parts:
            modules_idx = parts.index('modules')
            if modules_idx + 2 < len(parts):
                return f"{parts[modules_idx+1]}.{parts[modules_idx+2]}"
        elif 'holo_index' in path:
            return 'holo_index'
        return path.split('/')[-2] if '/' in path else 'unknown'

    def _analyze_code_at_cursor(self, file_path: str, line: int) -> Optional[Dict[str, Any]]:
        """Analyze the code around the cursor position to understand the task."""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            if line < len(lines):
                # Get context around cursor (5 lines before and after)
                start_line = max(0, line - 5)
                end_line = min(len(lines), line + 6)
                context_lines = lines[start_line:end_line]

                # Analyze the code for patterns
                context_text = ''.join(context_lines).lower()

                # Look for specific development patterns
                if 'integration' in context_text or 'connect' in context_text:
                    return {
                        'task_type': 'integration',
                        'description': 'Working on system integration',
                        'confidence': 0.8
                    }
                elif 'throttle' in context_text or 'quota' in context_text:
                    return {
                        'task_type': 'optimization',
                        'description': 'Optimizing resource usage',
                        'confidence': 0.9
                    }
                elif 'test' in context_text or 'fix' in context_text:
                    return {
                        'task_type': 'bug_fix',
                        'description': 'Fixing bugs or adding tests',
                        'confidence': 0.7
                    }

        except Exception as e:
            print(f"Error analyzing code at cursor: {e}")

        return None

    def _generate_task_description(self, task_info: Dict) -> str:
        """Generate a human-readable task description."""
        task_type = task_info.get('task_type', 'unknown')
        active_module = task_info.get('active_module', 'unknown')

        descriptions = {
            'integration': f"Integrating systems in {active_module}",
            'optimization': f"Optimizing performance in {active_module}",
            'enhancement': f"Enhancing capabilities in {active_module}",
            'bug_fix': f"Fixing issues in {active_module}",
            'unknown': f"Working on {active_module}"
        }

        return descriptions.get(task_type, descriptions['unknown'])

    def get_live_code_map(self, agent_id: str) -> Dict[str, Any]:
        """
        Generate a live code map showing exactly what the agent is working on.

        Returns a comprehensive map including:
        - Current task and description
        - Active module and exact location
        - Related modules and dependencies
        - Navigation suggestions
        """
        print(f"[CODE-MAP] DAECubeCodeMap: Generating live code map for agent {agent_id}")

        code_map = {
            'agent_id': agent_id,
            'timestamp': datetime.now().isoformat(),
            'current_task': {},
            'navigation_suggestions': [],
            'confidence': 0.0
        }

        # Get current cursor position and recent activity
        cursor_pos = self.cursor_positions.get(agent_id)
        if cursor_pos:
            file_path, line, column = cursor_pos
            code_map['cursor_position'] = {
                'file': file_path,
                'line': line,
                'column': column
            }
            print(f"[CODE-MAP] Cursor position detected: {file_path}:{line}")

        # Detect current task
        task_info = self.detect_current_task(agent_id)
        code_map['current_task'] = task_info
        code_map['confidence'] = task_info.get('confidence', 0.0)

        print(f"[CODE-MAP] Task detected: {task_info.get('description', 'Unknown')} (confidence: {task_info.get('confidence', 0.0):.2f})")

        # Generate navigation suggestions
        code_map['navigation_suggestions'] = self._generate_navigation_suggestions(task_info)

        print(f"[CODE-MAP] Generated {len(code_map['navigation_suggestions'])} navigation suggestions")
        return code_map

    def _generate_navigation_suggestions(self, task_info: Dict) -> List[str]:
        """Generate intelligent navigation suggestions based on current task."""
        suggestions = []
        task_type = task_info.get('task_type', 'unknown')
        active_module = task_info.get('active_module', '')

        if task_type == 'integration':
            suggestions.extend([
                f"Check {active_module} dependencies",
                "Look for existing integration patterns",
                "Review module interfaces and APIs"
            ])
        elif task_type == 'optimization':
            suggestions.extend([
                f"Check {active_module} performance metrics",
                "Look for throttling and caching mechanisms",
                "Review resource usage patterns"
            ])
        elif task_type == 'bug_fix':
            suggestions.extend([
                f"Check {active_module} test coverage",
                "Look for error handling patterns",
                "Review recent changes and commits"
            ])

        return suggestions


class DAECubeOrganizer:
    """
    DAE Cube Organizer - The foundational intelligence layer.

    Provides immediate DAE context and structure understanding,
    eliminating the need for 0102 agents to compute DAE relationships.
    """

    def __init__(self):
        self.dae_cubes = self._initialize_dae_cubes()
        self.module_registry = self._build_module_registry()
        self.main_py_analysis = self._analyze_main_py()

    def _initialize_dae_cubes(self) -> Dict[str, DAECube]:
        """Initialize the known DAE cube structures."""
        return {
            "youtube_dae": DAECube(
                name="YouTube Live DAE",
                description="Real-time YouTube chat moderation and gamification system",
                orchestrator="AutoModeratorDAE",
                modules=[
                    "communication/livechat",
                    "platform_integration/stream_resolver",
                    "platform_integration/youtube_auth",
                    "platform_integration/social_media_orchestrator",
                    "gamification/whack_a_magat",
                    "infrastructure/instance_lock"
                ],
                responsibilities=[
                    "Stream detection and monitoring",
                    "Chat message processing and moderation",
                    "Gamification (XP/ranks/levels)",
                    "Social media posting automation",
                    "Multi-channel support (Move2Japan, UnDaoDu, FoundUps)",
                    "Throttling and API quota management"
                ],
                main_py_reference="Option 1: monitor_youtube()"
            ),

            "amo_dae": DAECube(
                name="Autonomous Meeting Orchestrator",
                description="Recursive multi-agent conversation and scheduling system",
                orchestrator="AutoModeratorDAE",
                modules=[
                    "communication/livechat",
                    "ai_intelligence/0102_orchestrator",
                    "infrastructure/wre_core"
                ],
                responsibilities=[
                    "Meeting scheduling and coordination",
                    "Multi-agent conversation orchestration",
                    "Recursive improvement cycles",
                    "Session management and logging"
                ],
                main_py_reference="Option 2: run_amo_dae()"
            ),

            "social_media_dae": DAECube(
                name="Social Media DAE (012 Digital Twin)",
                description="Automated social media presence and engagement system",
                orchestrator="SocialMediaDAE",
                modules=[
                    "platform_integration/social_media_orchestrator",
                    "platform_integration/linkedin_agent",
                    "platform_integration/x_twitter",
                    "ai_intelligence/social_media_dae"
                ],
                responsibilities=[
                    "LinkedIn company page management",
                    "X/Twitter automation and engagement",
                    "Content scheduling and posting",
                    "Digital twin maintenance",
                    "Multi-platform orchestration"
                ],
                main_py_reference="Option 3: run_social_media_dae()"
            ),

            "pqn_dae": DAECube(
                name="P&Q Orchestration DAE",
                description="Quantum research, pattern detection, and rESP analysis system",
                orchestrator="PQNResearchDAEOrchestrator",
                modules=[
                    "ai_intelligence/pqn_alignment",
                    "ai_intelligence/rESP_o1o2",
                    "infrastructure/database"
                ],
                responsibilities=[
                    "PQN alignment validation campaigns",
                    "rESP detector processing and analysis",
                    "Quantum coherence pattern research",
                    "Database-backed learning and memory",
                    "Cross-validation and statistical analysis"
                ],
                main_py_reference="Option 4: run_pqn_dae()"
            ),

            "developer_ops_dae": DAECube(
                name="Developer Ops Orchestrator",
                description="Remote builds, Git integration, and development operations",
                orchestrator="GitOpsOrchestrator",
                modules=[
                    "platform_integration/remote_builder",
                    "infrastructure/git_integration",
                    "development/module_creator"
                ],
                responsibilities=[
                    "Remote repository management",
                    "Automated build and deployment",
                    "ModLog synchronization",
                    "Module scaffolding and creation"
                ],
                main_py_reference="Option 0: git_push_and_post()"
            )
        }

    def _build_module_registry(self) -> Dict[str, DAEModule]:
        """Build comprehensive module registry from codebase."""
        registry = {}

        # Scan modules directory for actual modules
        modules_dir = Path("modules")
        if modules_dir.exists():
            for domain_dir in modules_dir.iterdir():
                if domain_dir.is_dir() and not domain_dir.name.startswith('.'):
                    domain = domain_dir.name

                    for module_dir in domain_dir.iterdir():
                        if module_dir.is_dir() and not module_dir.name.startswith('.'):
                            module_name = module_dir.name
                            module_path = f"{domain}/{module_name}"

                            # Try to read README for description
                            readme_path = module_dir / "README.md"
                            description = f"{domain} {module_name} module"
                            if readme_path.exists():
                                try:
                                    with open(readme_path, 'r', encoding='utf-8') as f:
                                        content = f.read()
                                        # Extract first meaningful line after title
                                        lines = content.split('\n')
                                        for line in lines[1:5]:
                                            line = line.strip()
                                            if line and not line.startswith('#') and len(line) > 10:
                                                description = line
                                                break
                                except:
                                    pass

                            registry[module_path] = DAEModule(
                                name=module_name,
                                path=module_path,
                                domain=domain,
                                description=description
                            )

        return registry

    def _analyze_main_py(self) -> Dict[str, Any]:
        """Analyze main.py to understand DAE orchestration."""
        analysis = {
            "dae_options": {},
            "orchestrators": set(),
            "imports": set()
        }

        try:
            with open("main.py", 'r', encoding='utf-8') as f:
                content = f.read()

            # Extract DAE option descriptions from menu
            menu_matches = re.findall(r'(\d+)\.\s*([^(\n]+)', content)
            for num, desc in menu_matches:
                if num in ['1', '2', '3', '4', '0']:
                    analysis["dae_options"][num] = desc.strip()

            # Extract orchestrator imports
            import_matches = re.findall(r'from\s+modules\.[^\'"]*\s+import\s+([^\'"\n]+)', content)
            for match in import_matches:
                if 'DAE' in match or 'Orchestrator' in match:
                    analysis["orchestrators"].add(match)

            # Extract function definitions
            func_matches = re.findall(r'def\s+(run_\w+_dae|monitor_\w+|git_push_and_post)', content)
            analysis["functions"] = list(set(func_matches))

        except Exception as e:
            logger.warning(f"Could not analyze main.py: {e}")

        return analysis

    def initialize_dae_context(self, dae_focus: Optional[str] = None) -> Dict[str, Any]:
        """
        Initialize DAE context for 0102 agent rampup.

        Args:
            dae_focus: The DAE that 012 wants 0102 to become (optional)

        Returns:
            Complete DAE context and structure information
        """
        if dae_focus:
            detected_dae = self._detect_dae_from_focus(dae_focus)
        else:
            detected_dae = self._detect_active_dae()

        context = {
            "dae_identity": self._get_dae_identity(detected_dae),
            "cube_structure": self._get_cube_structure(detected_dae),
            "module_map": self._get_module_map(detected_dae),
            "orchestration_flow": self._get_orchestration_flow(detected_dae),
            "health_status": self._get_health_status(detected_dae),
            "quick_reference": self._get_quick_reference(detected_dae),
            "rampup_guidance": self._get_rampup_guidance(detected_dae)
        }

        return context

    def _detect_dae_from_focus(self, dae_focus: str) -> str:
        """Detect DAE from 012's focus instruction."""
        focus_lower = dae_focus.lower()

        # Map common focus descriptions to DAE keys
        focus_mapping = {
            "youtube": "youtube_dae",
            "live chat": "youtube_dae",
            "moderation": "amo_dae",
            "meeting": "amo_dae",
            "autonomous meeting": "amo_dae",
            "social media": "social_media_dae",
            "digital twin": "social_media_dae",
            "linkedin": "social_media_dae",
            "twitter": "social_media_dae",
            "pqn": "pqn_dae",
            "quantum": "pqn_dae",
            "research": "pqn_dae",
            "resp": "pqn_dae",
            "developer": "developer_ops_dae",
            "git": "developer_ops_dae",
            "remote build": "developer_ops_dae"
        }

        for keyword, dae_key in focus_mapping.items():
            if keyword in focus_lower:
                return dae_key

        return "youtube_dae"  # Default fallback

    def _detect_active_dae(self) -> str:
        """Detect currently active DAE from system state."""
        # Check for running processes or recent activity
        # For now, default to youtube_dae as it's the most active
        return "youtube_dae"

    def _get_dae_identity(self, dae_key: str) -> Dict[str, Any]:
        """Get DAE identity information."""
        dae = self.dae_cubes.get(dae_key)
        if not dae:
            return {"error": f"Unknown DAE: {dae_key}"}

        return {
            "name": dae.name,
            "description": dae.description,
            "orchestrator": dae.orchestrator,
            "main_py_reference": dae.main_py_reference,
            "emoji": self._get_dae_emoji(dae_key)
        }

    def _get_dae_emoji(self, dae_key: str) -> str:
        """Get emoji representation for DAE."""
        emoji_map = {
            "youtube_dae": "ðŸ“º",
            "amo_dae": "ðŸ§ ",
            "social_media_dae": "ðŸ“¢",
            "pqn_dae": "ðŸ§¬",
            "developer_ops_dae": "âš™ï¸"
        }
        return emoji_map.get(dae_key, "ðŸ”§")

    def _get_cube_structure(self, dae_key: str) -> Dict[str, Any]:
        """Get complete cube structure with modules and connections."""
        dae = self.dae_cubes.get(dae_key)
        if not dae:
            return {"error": f"Unknown DAE: {dae_key}"}

        structure = {
            "orchestrator": {
                "name": dae.orchestrator,
                "responsibilities": dae.responsibilities
            },
            "modules": {},
            "connections": self._analyze_module_connections(dae_key)
        }

        # Add detailed module information
        for module_path in dae.modules:
            module = self.module_registry.get(module_path)
            if module:
                structure["modules"][module_path] = {
                    "name": module.name,
                    "domain": module.domain,
                    "description": module.description,
                    "health_score": module.health_score
                }

        return structure

    def _analyze_module_connections(self, dae_key: str) -> List[Dict[str, str]]:
        """Analyze how modules connect within the DAE."""
        connections = []

        if dae_key == "youtube_dae":
            connections = [
                {"from": "stream_resolver", "to": "auto_moderator_dae", "purpose": "Stream detection â†’ Chat processing"},
                {"from": "auto_moderator_dae", "to": "social_media_orchestrator", "purpose": "Stream start â†’ Social posting"},
                {"from": "youtube_auth", "to": "stream_resolver", "purpose": "Authentication â†’ Stream access"},
                {"from": "instance_lock", "to": "auto_moderator_dae", "purpose": "Process management â†’ Safe execution"}
            ]
        elif dae_key == "pqn_dae":
            connections = [
                {"from": "pqn_alignment", "to": "pqn_research_dae_orchestrator", "purpose": "Research campaigns â†’ Orchestration"},
                {"from": "rESP_o1o2", "to": "pqn_research_dae_orchestrator", "purpose": "Detector analysis â†’ Research coordination"},
                {"from": "database", "to": "pqn_alignment", "purpose": "Data persistence â†’ Research continuity"}
            ]

        return connections

    def _get_module_map(self, dae_key: str) -> Dict[str, Any]:
        """Get visual module map for the DAE."""
        dae = self.dae_cubes.get(dae_key)
        if not dae:
            return {}

        # Create ASCII art style module map
        module_map = f"""
{self._get_dae_emoji(dae_key)} {dae.name}
{'=' * (len(dae.name) + 2)}

ðŸŽ¯ ORCHESTRATOR
    â””â”€â”€ {dae.orchestrator}

ðŸ“¦ MODULES
"""

        for module_path in dae.modules:
            module = self.module_registry.get(module_path)
            if module:
                domain_emoji = self._get_domain_emoji(module.domain)
                module_map += f"    â”œâ”€â”€ {domain_emoji} {module.name}\n"
                module_map += f"    â”‚   â””â”€â”€ {module.description[:50]}...\n"

        module_map += f"\nðŸ”„ RESPONSIBILITIES\n"
        for resp in dae.responsibilities[:3]:
            module_map += f"    â€¢ {resp}\n"

        return {"ascii_map": module_map.strip(), "module_count": len(dae.modules)}

    def _get_domain_emoji(self, domain: str) -> str:
        """Get emoji for domain."""
        domain_emojis = {
            "communication": "ðŸ’¬",
            "platform_integration": "ðŸ”Œ",
            "ai_intelligence": "ðŸ§ ",
            "infrastructure": "ðŸ—ï¸",
            "gamification": "ðŸŽ®",
            "development": "âš™ï¸"
        }
        return domain_emojis.get(domain, "ðŸ“¦")

    def _get_orchestration_flow(self, dae_key: str) -> Dict[str, Any]:
        """Get orchestration flow for the DAE."""
        flows = {
            "youtube_dae": {
                "phases": [
                    "ðŸ” Stream Detection (stream_resolver)",
                    "ðŸ” Authentication (youtube_auth)",
                    "ðŸ’¬ Chat Processing (auto_moderator_dae)",
                    "ðŸŽ® Gamification (whack_a_magat)",
                    "ðŸ“¢ Social Posting (social_media_orchestrator)"
                ],
                "loop_type": "continuous_stream_monitoring",
                "error_handling": "instance_lock_prevention"
            },
            "pqn_dae": {
                "phases": [
                    "ðŸ§¬ Research Campaign Setup (pqn_alignment)",
                    "ðŸ”¬ rESP Analysis (rESP_o1o2)",
                    "ðŸ’¾ Data Persistence (database)",
                    "ðŸ“Š Cross-Validation (pqn_research_dae_orchestrator)"
                ],
                "loop_type": "research_campaign_cycles",
                "error_handling": "statistical_validation"
            }
        }

        return flows.get(dae_key, {"phases": ["Orchestration flow not defined"]})

    def _get_health_status(self, dae_key: str) -> Dict[str, Any]:
        """Get health status for the DAE."""
        # This would integrate with actual health monitoring
        # For now, provide mock health status
        return {
            "overall_status": "healthy",
            "module_health": "4/4 modules operational",
            "last_check": datetime.now().isoformat(),
            "issues": []
        }

    def _get_quick_reference(self, dae_key: str) -> Dict[str, Any]:
        """Get quick reference information."""
        dae = self.dae_cubes.get(dae_key)
        if not dae:
            return {}

        return {
            "menu_option": dae.main_py_reference,
            "key_modules": dae.modules[:3],
            "primary_responsibility": dae.responsibilities[0] if dae.responsibilities else "",
            "emergency_contacts": ["Check main.py logs", "Verify instance locks"]
        }

    def _get_rampup_guidance(self, dae_key: str) -> Dict[str, Any]:
        """Get rampup guidance for 0102 agent."""
        guidance = {
            "immediate_focus": "Understand the orchestrator and module connections",
            "key_resources": [
                "Read orchestrator source code",
                "Check module READMEs",
                "Review main.py integration points"
            ],
            "avoid_common_pitfalls": [
                "Don't modify core orchestration logic without testing",
                "Always check instance locks before starting",
                "Verify module health before assuming functionality"
            ],
            "success_indicators": [
                "Orchestrator initializes without errors",
                "Modules connect and communicate properly",
                "DAE achieves its primary responsibilities"
            ]
        }

        # DAE-specific guidance
        if dae_key == "youtube_dae":
            guidance["special_notes"] = [
                "Multi-channel support requires careful API quota management",
                "Instance locking is critical for preventing conflicts",
                "Stream detection should be tested across all channels"
            ]
        elif dae_key == "pqn_dae":
            guidance["special_notes"] = [
                "Database integrity is critical for research continuity",
                "Statistical validation should be verified regularly",
                "Cross-validation campaigns require significant compute"
            ]

        return guidance
