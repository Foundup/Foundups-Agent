# -*- coding: utf-8 -*-

"""
# === UTF-8 ENFORCEMENT (WSP 90) ===
# Prevent UnicodeEncodeError on Windows systems
if sys.platform.startswith('win'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
# === END UTF-8 ENFORCEMENT ===

Test Gemma RAG Inference Integration with Pattern Memory

Tests the complete flow:
1. Pattern memory with 012.txt patterns
2. Gemma inference with RAG
3. Adaptive routing to Qwen
4. Performance metrics

NAVIGATION: Test suite for Gemma/Qwen adaptive routing
-> Tests: gemma_rag_inference.py, pattern_memory.py
-> Models: E:/HoloIndex/models/gemma-3-270m-it-Q4_K_M.gguf, qwen-coder-1.5b.gguf
"""

from pathlib import Path
import sys
import io

# Fix Windows console encoding for Unicode output
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from holo_index.qwen_advisor.gemma_rag_inference import GemmaRAGInference
from holo_index.qwen_advisor.pattern_memory import PatternMemory


def test_pattern_memory_integration():
    """Test 1: Verify pattern memory has 012.txt patterns"""
    print("\n" + "="*60)
    print("TEST 1: Pattern Memory Integration")
    print("="*60)

    memory = PatternMemory()
    stats = memory.get_stats()

    print(f"✓ Pattern memory initialized")
    print(f"  Total patterns: {stats['total_patterns']}")
    print(f"  012.txt progress: {stats['checkpoint_line']}/28326")

    if stats['total_patterns'] == 0:
        print("\n⚠️  Warning: No patterns stored yet")
        print("   Run training first: python main.py → option 12 → option 1")
        return False

    # Test pattern recall
    test_query = "YouTube authentication module"
    patterns = memory.recall_similar(test_query, n=3, min_similarity=0.3)

    print(f"\n✓ Pattern recall test: '{test_query}'")
    print(f"  Retrieved {len(patterns)} relevant patterns")

    for i, pattern in enumerate(patterns, 1):
        context = pattern['context'][:100]
        similarity = pattern['similarity']
        print(f"  {i}. Similarity: {similarity:.2f} | Context: {context}...")

    return True


def test_gemma_inference():
    """Test 2: Gemma inference with correct model path"""
    print("\n" + "="*60)
    print("TEST 2: Gemma Inference")
    print("="*60)

    # Use correct model path from E:/HoloIndex/models/
    gemma_path = Path("E:/HoloIndex/models/gemma-3-270m-it-Q4_K_M.gguf")
    qwen_path = Path("E:/HoloIndex/models/qwen-coder-1.5b.gguf")

    if not gemma_path.exists():
        print(f"✗ Gemma model not found: {gemma_path}")
        return False

    if not qwen_path.exists():
        print(f"✗ Qwen model not found: {qwen_path}")
        return False

    print(f"✓ Gemma model found: {gemma_path}")
    print(f"✓ Qwen model found: {qwen_path}")

    # Initialize inference engine
    engine = GemmaRAGInference(
        gemma_model_path=gemma_path,
        qwen_model_path=qwen_path,
        confidence_threshold=0.7
    )

    print("\n✓ Inference engine initialized")
    return engine


def test_adaptive_routing(engine):
    """Test 3: Adaptive routing with different query types"""
    print("\n" + "="*60)
    print("TEST 3: Adaptive Routing")
    print("="*60)

    test_queries = [
        ("Which module handles YouTube authentication?", "simple"),
        ("How does priority scoring work for channels?", "medium"),
        ("Why did Move2Japan get score 1.00?", "complex"),
        ("Where should test files be placed?", "simple"),
    ]

    results = []

    for query, expected_complexity in test_queries:
        print(f"\n[QUERY] {query}")
        print(f"[EXPECTED] {expected_complexity}")

        result = engine.infer(query)

        print(f"[MODEL] {result.model_used}")
        print(f"[LATENCY] {result.latency_ms}ms")
        print(f"[CONFIDENCE] {result.confidence:.2f}")
        print(f"[PATTERNS] {result.patterns_used}")

        if result.escalated:
            print(f"[ESCALATED] {result.escalation_reason}")

        print(f"[RESPONSE] {result.response[:100]}...")

        results.append(result)

    return results


def test_performance_stats(engine, results):
    """Test 4: Performance statistics and targets"""
    print("\n" + "="*60)
    print("TEST 4: Performance Statistics")
    print("="*60)

    stats = engine.get_stats()

    print(f"Total Queries: {stats['total_queries']}")
    print(f"Gemma Handled: {stats['gemma_handled']} ({stats['gemma_percentage']:.1f}%)")
    print(f"Qwen Escalated: {stats['qwen_escalated']} ({stats['qwen_percentage']:.1f}%)")

    # Calculate average latencies
    gemma_latencies = [r.latency_ms for r in results if r.model_used == "gemma-3-270m"]
    qwen_latencies = [r.latency_ms for r in results if r.model_used == "qwen-1.5b"]

    if gemma_latencies:
        avg_gemma = sum(gemma_latencies) / len(gemma_latencies)
        print(f"Avg Gemma Latency: {avg_gemma:.0f}ms")

    if qwen_latencies:
        avg_qwen = sum(qwen_latencies) / len(qwen_latencies)
        print(f"Avg Qwen Latency: {avg_qwen:.0f}ms")

    print(f"\n[TARGET] 70% Gemma / 30% Qwen")
    print(f"[ACTUAL] {stats['gemma_percentage']:.1f}% Gemma / {stats['qwen_percentage']:.1f}% Qwen")

    # Check if within target range (±20%)
    gemma_target_met = 50 <= stats['gemma_percentage'] <= 90
    qwen_target_met = 10 <= stats['qwen_percentage'] <= 50

    if gemma_target_met and qwen_target_met:
        print("\n✓ Performance targets met!")
    else:
        print("\n⚠️  Performance targets need tuning")
        print("   Adjust confidence_threshold or complexity classification")


def main():
    """Run complete test suite"""
    print("\n" + "="*60)
    print("GEMMA RAG INFERENCE TEST SUITE")
    print("WRE Pattern: 012 → 0102 → Qwen → Gemma")
    print("="*60)

    # Test 1: Pattern Memory
    if not test_pattern_memory_integration():
        print("\n✗ Test suite aborted: No patterns in memory")
        print("   Run training first: python main.py → option 12 → option 1")
        return

    # Test 2: Gemma Inference Setup
    engine = test_gemma_inference()
    if not engine:
        print("\n✗ Test suite aborted: Model setup failed")
        return

    # Test 3: Adaptive Routing
    results = test_adaptive_routing(engine)

    # Test 4: Performance Stats
    test_performance_stats(engine, results)

    print("\n" + "="*60)
    print("TEST SUITE COMPLETE")
    print("="*60)
    print("\n✓ All tests passed")
    print("✓ Gemma RAG inference operational")
    print("✓ Adaptive routing functional")
    print("✓ Pattern memory integration working")

    print("\n[NEXT STEPS]")
    print("1. Integrate into main.py menu (option 12 → option 4)")
    print("2. Add live chat training integration")
    print("3. Monitor performance in production")


if __name__ == "__main__":
    main()
