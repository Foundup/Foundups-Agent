# WSP: Native Skills System Architecture (Qwen/Gemma)

**Critical Architectural Decision - 2025-10-20**

---

## Problem Statement

**Claude Code Skills only work for 0102** (Claude Sonnet in the Claude Code CLI environment). They require:
- Code Execution capability
- Anthropic's progressive disclosure system
- Claude.ai/API infrastructure

**But our multi-agent system needs Skills for Qwen and Gemma**, which are:
- Running locally (not through Anthropic API)
- Executing in Python environments
- Coordinating via WSP framework and MCP servers

**Therefore**: We must build a **NATIVE Skills system** that trains Qwen/Gemma to model the Claude Code pattern independently.

---

## 1. Architectural Vision

### 1.1 Dual Skills Systems

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FOUNDUPS SKILLS ECOSYSTEM                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LAYER 1: CLAUDE CODE SKILLS (.claude/skills/)
â”œâ”€â”€ Purpose: 0102 agent task-specific instructions
â”œâ”€â”€ Format: SKILL.md with YAML frontmatter
â”œâ”€â”€ Invocation: Anthropic's auto-discovery
â”œâ”€â”€ Execution: Claude Code CLI environment
â””â”€â”€ Examples:
    â”œâ”€â”€ qwen_wsp_enhancement/SKILL.md
    â””â”€â”€ youtube_dae/SKILL.md

LAYER 2: NATIVE SKILLS (modules/*/skills/)
â”œâ”€â”€ Purpose: Qwen/Gemma task-specific instructions
â”œâ”€â”€ Format: SKILL.md (same format, different loading mechanism)
â”œâ”€â”€ Invocation: WSP Orchestrator + MCP discovery
â”œâ”€â”€ Execution: Python/local model environment
â””â”€â”€ Examples:
    â”œâ”€â”€ modules/communication/livechat/skills/
    â”‚   â”œâ”€â”€ youtube_moderation.md
    â”‚   â”œâ”€â”€ banter_response.md
    â”‚   â””â”€â”€ stream_detection.md
    â”œâ”€â”€ modules/infrastructure/wsp_orchestrator/skills/
    â”‚   â”œâ”€â”€ wsp_analysis.md
    â”‚   â”œâ”€â”€ protocol_enhancement.md
    â”‚   â””â”€â”€ gap_detection.md
    â””â”€â”€ holo_index/skills/
        â”œâ”€â”€ semantic_search.md
        â”œâ”€â”€ module_analysis.md
        â””â”€â”€ vibecoding_detection.md
```

### 1.2 Key Principle

**"Every agent task should have a Skills.md file"**

When Qwen or Gemma is assigned a task, the WSP Orchestrator:
1. Checks if a relevant skill exists in the module's `skills/` directory
2. Loads the SKILL.md into the agent's prompt
3. Agent executes following the instructions
4. Breadcrumb telemetry logs adherence to instructions
5. Gemma scores pattern fidelity (did agent follow the skill?)
6. System updates SKILL.md based on performance (recursive evolution)

---

## 2. Implementation Strategy

### 2.1 Phase 1: Prototype with Claude Code

**Build the pattern FIRST in `.claude/skills/`** where 0102 can validate it works:

```bash
# Step 1: Create prototype skill in Claude Code environment
.claude/skills/
â””â”€â”€ youtube_moderation_prototype/
    â”œâ”€â”€ SKILL.md
    â”œâ”€â”€ examples/
    â”‚   â”œâ”€â”€ spam_detection_examples.md
    â”‚   â””â”€â”€ toxic_content_patterns.md
    â””â”€â”€ metrics/
        â””â”€â”€ pattern_fidelity_baseline.json
```

**0102 validates**:
- Instructions are clear
- Examples are sufficient
- Pattern fidelity can be measured
- Skill achieves > 90% success rate

### 2.2 Phase 2: Extract to Native Format

**Once validated, extract to module's `skills/` directory**:

```bash
# Step 2: Deploy to native Qwen/Gemma environment
modules/communication/livechat/skills/
â””â”€â”€ youtube_moderation/
    â”œâ”€â”€ SKILL.md              # Same content as Claude Code version
    â”œâ”€â”€ examples/
    â”œâ”€â”€ metrics/
    â”‚   â”œâ”€â”€ pattern_fidelity.json
    â”‚   â””â”€â”€ outcome_quality.json
    â”œâ”€â”€ versions/             # Evolution tracking
    â”‚   â”œâ”€â”€ v1.0_baseline.md
    â”‚   â””â”€â”€ v1.1_improved_spam_detection.md
    â””â”€â”€ CHANGELOG.md
```

### 2.3 Phase 3: Train Qwen/Gemma to Load Skills

**Implement native skill loading in WSP Orchestrator**:

```python
# modules/infrastructure/wsp_orchestrator/src/skill_loader.py

class NativeSkillLoader:
    """Load Skills.md for Qwen/Gemma agents (mirrors Claude Code pattern)"""

    def __init__(self, base_path: Path = Path("O:/Foundups-Agent")):
        self.base_path = base_path
        self.skill_cache = {}  # Progressive disclosure cache

    def discover_skills(self, module_path: str) -> List[Dict]:
        """
        Scan module's skills/ directory for available skills.
        Returns: List of {name, description, path} dicts
        """
        skills_dir = self.base_path / module_path / "skills"
        if not skills_dir.exists():
            return []

        skills = []
        for skill_dir in skills_dir.iterdir():
            if skill_dir.is_dir() and (skill_dir / "SKILL.md").exists():
                # Parse YAML frontmatter (name + description only)
                skill_meta = self._parse_frontmatter(skill_dir / "SKILL.md")
                skills.append({
                    "name": skill_meta["name"],
                    "description": skill_meta["description"],
                    "path": skill_dir / "SKILL.md"
                })
        return skills

    def load_skill(self, skill_path: Path) -> str:
        """
        Load full SKILL.md content (lazy loading, like Claude Code).
        Caches for session duration.
        """
        if skill_path in self.skill_cache:
            return self.skill_cache[skill_path]

        with open(skill_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.skill_cache[skill_path] = content
        return content

    def inject_skill_into_prompt(self, base_prompt: str, skill_content: str) -> str:
        """
        Inject skill instructions into agent prompt.
        Mimics Claude Code's progressive disclosure.
        """
        return f"""{base_prompt}

# ACTIVE SKILL

You are now executing a task using the following skill instructions:

{skill_content}

CRITICAL: Follow these skill instructions precisely. Your adherence will be scored.
"""

# Usage in WSP Orchestrator:

def assign_task_to_qwen(task_description: str, module: str):
    """Assign task to Qwen with relevant skill loaded"""

    # Discover available skills
    skill_loader = NativeSkillLoader()
    available_skills = skill_loader.discover_skills(module)

    # Select relevant skill (simple keyword matching for now)
    relevant_skill = select_skill_by_keywords(task_description, available_skills)

    if relevant_skill:
        # Load full skill content
        skill_content = skill_loader.load_skill(relevant_skill["path"])

        # Inject into Qwen's prompt
        enhanced_prompt = skill_loader.inject_skill_into_prompt(
            base_prompt=QWEN_BASE_PROMPT,
            skill_content=skill_content
        )

        # Execute task with skill-enhanced prompt
        qwen_response = qwen_engine.execute(
            prompt=enhanced_prompt,
            task=task_description
        )

        # Log skill usage for pattern fidelity scoring
        log_skill_execution(
            skill_name=relevant_skill["name"],
            task=task_description,
            breadcrumbs=qwen_response.breadcrumbs
        )

        return qwen_response
    else:
        # No skill found - execute with base prompt
        return qwen_engine.execute(QWEN_BASE_PROMPT, task_description)
```

### 2.4 Phase 4: Integrate with Gemma Pattern Scoring

**Gemma validates if Qwen followed the skill instructions**:

```python
# modules/ai_intelligence/gemma_pattern_validator/src/pattern_scorer.py

class GemmaPatternScorer:
    """Score how well Qwen/agents followed skill instructions"""

    def score_skill_adherence(
        self,
        skill_instructions: List[str],  # Parsed from SKILL.md
        agent_breadcrumbs: List[Dict]   # Telemetry from execution
    ) -> Dict:
        """
        For each instruction in skill, did agent follow it?
        Returns: {instruction_id: {followed: bool, confidence: float}}
        """

        results = {}
        for idx, instruction in enumerate(skill_instructions):
            # Gemma binary classification: Did agent follow this instruction?
            followed = self._classify_instruction_adherence(
                instruction=instruction,
                breadcrumbs=agent_breadcrumbs
            )

            results[f"instruction_{idx}"] = {
                "text": instruction,
                "followed": followed["decision"],  # True/False
                "confidence": followed["confidence"],
                "evidence": followed["breadcrumb_matches"]
            }

        # Calculate overall pattern fidelity
        pattern_fidelity = sum(
            1 for r in results.values() if r["followed"]
        ) / len(results)

        return {
            "instruction_scores": results,
            "pattern_fidelity": pattern_fidelity,
            "threshold_met": pattern_fidelity >= 0.90
        }

    def _classify_instruction_adherence(
        self,
        instruction: str,
        breadcrumbs: List[Dict]
    ) -> Dict:
        """Gemma 3 270M fast classification"""

        prompt = f"""Did the agent follow this instruction?

Instruction: {instruction}

Agent actions (breadcrumbs):
{json.dumps(breadcrumbs, indent=2)}

Answer: Yes/No
Confidence: 0.0-1.0
Evidence: Which breadcrumb(s) prove it?
"""

        gemma_response = self.gemma_engine.classify(prompt)
        return {
            "decision": gemma_response.answer == "Yes",
            "confidence": gemma_response.confidence,
            "breadcrumb_matches": gemma_response.evidence
        }
```

---

## 3. Skills as Trainable Weights

### 3.1 The Neural Network Analogy

**Your Core Insight**:

> "These skills based on our system are treated like weights - they're living documents that are tweaked by the system based on the pattern results in the same way a neural network learns."

**Implementation**:

```
Neural Network:
  Weights â†’ Forward Pass â†’ Loss â†’ Backprop â†’ Weight Update

Skills System:
  Instructions â†’ Task Execution â†’ Pattern Score â†’ Variation Testing â†’ Instruction Update
```

### 3.2 Recursive Evolution Loop

```python
# holo_index/qwen_advisor/skill_evolution/recursive_trainer.py

class SkillEvolutionEngine:
    """Train Skills.md like neural network weights"""

    def evolve_skill(
        self,
        skill_path: Path,
        performance_threshold: float = 0.90
    ):
        """
        Recursive evolution loop for a single skill.
        Continues until pattern fidelity >= threshold.
        """

        iteration = 0
        converged = False

        while not converged and iteration < 10:  # Max 10 iterations
            # Load current skill version
            skill = self.load_skill(skill_path)

            # Execute on benchmark tasks
            results = self.run_benchmark_tasks(skill)

            # Calculate combined score
            pattern_fidelity = self.gemma_score_patterns(skill, results)
            outcome_quality = self.measure_outcome_quality(results)

            combined_score = (0.40 * pattern_fidelity) + (0.60 * outcome_quality)

            # Log metrics
            self.log_metrics(skill_path, iteration, combined_score)

            # Check convergence
            if combined_score >= performance_threshold:
                converged = True
                logger.info(f"âœ… Skill converged at v{iteration + 1}: {combined_score:.2%}")
                break

            # Generate variations (backpropagation analog)
            variations = self.qwen_generate_variations(
                skill=skill,
                failed_instructions=self.identify_weak_instructions(results),
                iteration=iteration
            )

            # A/B test variations
            best_variation = self.ab_test_variations(
                current=skill,
                variations=variations,
                benchmark_tasks=self.get_benchmark_tasks()
            )

            # Update skill if improvement found
            if best_variation.score > combined_score:
                self.update_skill(skill_path, best_variation.content)
                self.increment_version(skill_path)
                logger.info(f"ðŸ“ˆ Skill improved: {combined_score:.2%} â†’ {best_variation.score:.2%}")
            else:
                logger.warning(f"âš ï¸ No improvement found, retrying with different variations")

            iteration += 1

        # Save final metrics
        self.save_convergence_report(skill_path, iteration, combined_score, converged)
```

### 3.3 Version Control as Weight Checkpoints

```
skills/youtube_moderation/
â”œâ”€â”€ SKILL.md                    # Current version (v1.5)
â”œâ”€â”€ versions/
â”‚   â”œâ”€â”€ v1.0_baseline.md        # Checkpoint: Initial version
â”‚   â”œâ”€â”€ v1.1_add_caps_detection.md
â”‚   â”œâ”€â”€ v1.2_improve_toxic_patterns.md
â”‚   â”œâ”€â”€ v1.3_add_emoji_spam.md
â”‚   â”œâ”€â”€ v1.4_refine_rate_limiting.md
â”‚   â””â”€â”€ v1.5_add_context_awareness.md
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ v1.0_metrics.json       # {pattern_fidelity: 0.75, outcome_quality: 0.82}
â”‚   â”œâ”€â”€ v1.1_metrics.json       # {pattern_fidelity: 0.80, outcome_quality: 0.85}
â”‚   â”œâ”€â”€ v1.2_metrics.json       # {pattern_fidelity: 0.85, outcome_quality: 0.88}
â”‚   â”œâ”€â”€ v1.3_metrics.json       # {pattern_fidelity: 0.88, outcome_quality: 0.90}
â”‚   â”œâ”€â”€ v1.4_metrics.json       # {pattern_fidelity: 0.90, outcome_quality: 0.91}
â”‚   â””â”€â”€ v1.5_metrics.json       # {pattern_fidelity: 0.92, outcome_quality: 0.93} â† CONVERGED
â””â”€â”€ CHANGELOG.md
    # v1.5 (2025-10-25) - CONVERGENCE
    # - Pattern fidelity: 92% (threshold: 90%)
    # - Added context-awareness to reduce false positives
    # - 15% reduction in legitimate message blocks
    #
    # v1.4 (2025-10-24)
    # - Refined rate-limiting logic (variation #3 from A/B test)
    # - Improved detection of repeated short messages
    #
    # v1.3 (2025-10-23)
    # - Added emoji spam detection (>10 emojis in single message)
    # - Pattern fidelity increased from 85% â†’ 88%
```

---

## 4. WSP Integration: Skills in Every Module

### 4.1 Module Structure Enhancement

**Every module should have a `skills/` directory**:

```
modules/
â”œâ”€â”€ communication/
â”‚   â”œâ”€â”€ livechat/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ skills/              # â† NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ youtube_moderation/
â”‚   â”‚   â”‚   â”œâ”€â”€ banter_response/
â”‚   â”‚   â”‚   â””â”€â”€ stream_detection/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ auto_meeting_orchestrator/
â”‚       â”œâ”€â”€ src/
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ skills/              # â† NEW
â”‚       â”‚   â”œâ”€â”€ intent_creation/
â”‚       â”‚   â”œâ”€â”€ presence_aggregation/
â”‚       â”‚   â””â”€â”€ meeting_launch/
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ wsp_orchestrator/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ skills/              # â† NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ wsp_analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ protocol_enhancement/
â”‚   â”‚   â”‚   â””â”€â”€ gap_detection/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ dae_infrastructure/
â”‚       â””â”€â”€ foundups_vision_dae/
â”‚           â”œâ”€â”€ src/
â”‚           â”œâ”€â”€ tests/
â”‚           â”œâ”€â”€ skills/          # â† NEW
â”‚           â”‚   â”œâ”€â”€ telemetry_batching/
â”‚           â”‚   â”œâ”€â”€ session_reporting/
â”‚           â”‚   â””â”€â”€ worker_coordination/
â”‚           â””â”€â”€ README.md
â””â”€â”€ holo_index/
    â”œâ”€â”€ src/
    â”œâ”€â”€ tests/
    â”œâ”€â”€ skills/                  # â† NEW
    â”‚   â”œâ”€â”€ semantic_search/
    â”‚   â”œâ”€â”€ module_analysis/
    â”‚   â””â”€â”€ vibecoding_detection/
    â””â”€â”€ README.md
```

### 4.2 Discovery Protocol

**WSP Orchestrator auto-discovers module skills**:

```python
# When assigning task to Qwen/Gemma, WSP Orchestrator:

1. Determine which module the task relates to
   Example: "Moderate YouTube chat" â†’ modules/communication/livechat

2. Scan module's skills/ directory
   Found: youtube_moderation, banter_response, stream_detection

3. Match task keywords to skill descriptions
   Match: "Moderate" â†’ youtube_moderation/SKILL.md

4. Load skill (progressive disclosure):
   - First: name + description only (lightweight)
   - Then: Full SKILL.md content when task starts

5. Inject skill into agent prompt

6. Execute task with breadcrumb logging

7. Gemma scores pattern fidelity

8. Log metrics for skill evolution
```

### 4.3 WSP Compliance

**New WSP field**: `skills/` directory in module structure

```markdown
## WSP 49: Module Structure (UPDATED)

Every module MUST have:
- README.md
- INTERFACE.md
- src/
- tests/
- requirements.txt
- skills/              # â† NEW: Task-specific agent instructions
```

---

## 5. Migration Path

### 5.1 Current State

```
.claude/skills/                  # Claude Code skills (0102 only)
â”œâ”€â”€ qwen_wsp_enhancement/
â””â”€â”€ youtube_dae/
```

### 5.2 Target State

```
.claude/skills/                  # Claude Code skills (0102 prototyping)
â”œâ”€â”€ qwen_wsp_enhancement/        # Prototype validated by 0102
â””â”€â”€ youtube_dae/                 # Prototype validated by 0102

modules/communication/livechat/skills/   # Native Qwen/Gemma skills
â”œâ”€â”€ youtube_moderation/          # Extracted from Claude Code prototype
â”œâ”€â”€ banter_response/
â””â”€â”€ stream_detection/

modules/infrastructure/wsp_orchestrator/skills/
â”œâ”€â”€ wsp_analysis/                # Extracted from qwen_wsp_enhancement
â”œâ”€â”€ protocol_enhancement/
â””â”€â”€ gap_detection/

holo_index/skills/
â”œâ”€â”€ semantic_search/
â”œâ”€â”€ module_analysis/
â””â”€â”€ vibecoding_detection/
```

### 5.3 Migration Steps

**For each skill**:

1. **Prototype in `.claude/skills/`** (0102 validates)
2. **Extract to module `skills/`** (same SKILL.md format)
3. **Implement native loader** (WSP Orchestrator)
4. **Train Qwen/Gemma** (execute tasks with skills loaded)
5. **Enable pattern scoring** (Gemma validates adherence)
6. **Monitor metrics** (track pattern fidelity + outcome quality)
7. **Evolve recursively** (Qwen generates variations, A/B test, update)
8. **Converge** (pattern fidelity â‰¥ 90%)

---

## 6. Key Differences from Claude Code

| Aspect | Claude Code Skills | Native Skills (Qwen/Gemma) |
|--------|-------------------|---------------------------|
| **Environment** | Claude Code CLI | Python/local models |
| **Discovery** | Anthropic auto-discovery | WSP Orchestrator scan |
| **Loading** | Anthropic progressive disclosure | Manual injection into prompt |
| **Execution** | Code Execution tool | Direct Python execution |
| **Scoring** | None (manual feedback) | Gemma pattern fidelity scoring |
| **Evolution** | Manual updates | Automated recursive evolution |
| **Location** | `.claude/skills/` (global) | `modules/*/skills/` (per-module) |
| **Agent** | 0102 only | Qwen, Gemma, any local model |

---

## 7. Success Metrics

### 7.1 Skill Performance

- âœ… **Pattern Fidelity**: â‰¥ 90% (Gemma scores)
- âœ… **Outcome Quality**: â‰¥ 85% (012 feedback)
- âœ… **Combined Score**: â‰¥ 88% (weighted average)

### 7.2 System Adoption

- âœ… Every module has `skills/` directory
- âœ… Every agent task uses relevant skill
- âœ… Skills evolve automatically (no manual updates)
- âœ… Convergence achieved within 10 iterations

### 7.3 Efficiency Gains

- âœ… Token reduction: 50-200 (skill execution) vs 15K+ (manual)
- âœ… Time reduction: 2-5min (skill-guided) vs 15-30min (from scratch)
- âœ… Consistency improvement: 90%+ (skill) vs 60-75% (ad-hoc)

---

## 8. Next Steps

### Phase 1: Prototype (Week 1)
1. Select 1 skill to prototype: `youtube_moderation`
2. Build in `.claude/skills/youtube_moderation_prototype/`
3. Validate with 0102 (pattern fidelity â‰¥ 90%)
4. Document learnings

### Phase 2: Extract to Native (Week 2)
1. Deploy to `modules/communication/livechat/skills/youtube_moderation/`
2. Implement `NativeSkillLoader` in WSP Orchestrator
3. Test Qwen execution with skill loaded
4. Verify breadcrumb logging works

### Phase 3: Enable Scoring (Week 3)
1. Implement `GemmaPatternScorer`
2. Run benchmark tasks
3. Measure pattern fidelity
4. Collect baseline metrics

### Phase 4: Enable Evolution (Week 4)
1. Implement `SkillEvolutionEngine`
2. Qwen generates variations for low-scoring instructions
3. A/B test variations
4. Update skill based on results
5. Track convergence

### Phase 5: Scale (Ongoing)
1. Add skills for all modules
2. Automate skill creation (meta-skill)
3. Monitor system-wide skill performance
4. Continuous evolution loop

---

## 9. Architectural Principles

**012's Vision Captured**:

1. âœ… **Claude Code skills for 0102 only** - Prototyping environment
2. âœ… **Native skills for Qwen/Gemma** - Production execution
3. âœ… **Skills in every module** - WSP framework integration
4. âœ… **Skills = Weights** - Living documents that evolve
5. âœ… **Pattern-based learning** - Gemma scores, Qwen improves
6. âœ… **Recursive evolution** - Converge to 90%+ fidelity
7. âœ… **Neural network analogy** - Forward pass, loss, backprop, update

**Key Quote**:

> "Every time an agent is told to do something, there should be a skill for it. And these skills, based on our system, are treated like weights - living documents that are tweaked by the system based on the pattern results, in the same way a neural network learns."

---

**Status**: ARCHITECTURAL DESIGN COMPLETE
**Next**: Implement Phase 1 prototype (youtube_moderation skill)
**WSP Compliance**: NEW PROTOCOL (will become WSP 98: Native Skills System)
