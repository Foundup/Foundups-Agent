"""
Skill 1: Regular Engagement - Contextual replies for regular users (1âœ‹)

Extracted from intelligent_reply_generator.py lines 1039-1056
Phase 3O-3R Sprint 4 - Surgical skill extraction

WSP References:
- WSP 96 (WRE Skills): Skill separation pattern
- WSP 77 (Agent Coordination): Classification-based routing
- WSP 84 (Code Reuse): Reuses BanterEngine

Strategy Priority:
1. LLM contextual reply (if provided via context.llm_reply)
2. BanterEngine (theme-based banter, lazy-loaded)
3. Template responses (ultimate fallback)
"""

import logging
import random
from dataclasses import dataclass
from typing import Dict, Optional

logger = logging.getLogger(__name__)


@dataclass
class SkillContext:
    """
    Context for skill execution (WSP 96: Dependency injection pattern)

    Required fields:
        user_id: YouTube user/channel ID
        username: Display name
        comment_text: Comment content
        classification: User classification ('REGULAR' or 'SUBSCRIBER')
        confidence: Classification confidence (0.0-1.0)

    Optional fields:
        llm_reply: Pre-generated LLM reply (from Grok/LM Studio)
        theme: Banter theme for BanterEngine ('default', 'sarcastic', etc.)
        is_subscriber: Flag for subscriber-specific responses
    """
    user_id: str
    username: str
    comment_text: str
    classification: str
    confidence: float

    # Optional LLM reply (pre-generated by caller, like Skill 0's maga_response)
    llm_reply: Optional[str] = None

    # Optional banter theme
    theme: str = "default"

    # Optional subscriber flag (for future subscriber-specific responses)
    is_subscriber: bool = False


class RegularEngagementSkill:
    """
    Skill 1: Generate contextual, engaging replies for regular users (1âœ‹).

    Handles both regular viewers and subscribers in the new 0/1/2 classification system.

    Response Strategies (Priority Order):
    1. LLM Contextual Reply (if context.llm_reply provided)
    2. BanterEngine (theme-based, lazy-loaded)
    3. Template Responses (REGULAR_RESPONSES or SUBSCRIBER_RESPONSES)

    Pattern Source: intelligent_reply_generator.py lines 1039-1056
    """

    # Template responses for regular users (extracted from line 235-241)
    REGULAR_RESPONSES = [
        "Thanks for watching! ðŸŽŒ",
        "Great point! ðŸ‘",
        "Thanks for the comment! ðŸ˜Š",
        "Appreciate the feedback! ðŸ™",
        "Thanks for joining! ðŸŒŸ",
    ]

    # Template responses for subscribers (extracted from line 227-233)
    SUBSCRIBER_RESPONSES = [
        "Thanks for the support! ðŸŽŒ",
        "Arigatou gozaimasu! ðŸ‡¯ðŸ‡µ",
        "Appreciate you! ðŸ’™",
        "You're awesome! â­",
        "Thanks for being part of the community! ðŸ™Œ",
    ]

    def __init__(self):
        """Initialize skill with lazy-loaded dependencies."""
        self._banter_engine = None  # Lazy-loaded on first use
        logger.info("[SKILL-1] RegularEngagementSkill initialized (lazy dependencies)")

    def execute(self, context: SkillContext) -> Dict:
        """
        Execute skill to generate reply for regular user.

        Args:
            context: Skill execution context with user info and optional LLM reply

        Returns:
            Dict with:
                - reply_text: Generated reply
                - strategy: Which strategy was used
                - confidence: Reply confidence (0.0-1.0)
        """
        # STRATEGY 1: LLM contextual reply (if provided)
        if context.llm_reply:
            logger.info(f"[SKILL-1] Using pre-generated LLM reply (len={len(context.llm_reply)})")
            return {
                'reply_text': context.llm_reply,
                'strategy': 'llm_contextual',
                'confidence': 0.9
            }

        # STRATEGY 2: BanterEngine (theme-based, lazy-loaded)
        banter_reply = self._try_banter_engine(context.theme)
        if banter_reply:
            logger.info(f"[SKILL-1] BanterEngine reply (theme={context.theme})")
            return {
                'reply_text': banter_reply,
                'strategy': 'banter_engine',
                'confidence': 0.7
            }

        # STRATEGY 3: Template responses (ultimate fallback)
        if context.is_subscriber:
            templates = self.SUBSCRIBER_RESPONSES
            strategy = 'template_subscriber'
        else:
            templates = self.REGULAR_RESPONSES
            strategy = 'template_regular'

        reply = random.choice(templates)
        logger.info(f"[SKILL-1] Template fallback (strategy={strategy})")
        return {
            'reply_text': reply,
            'strategy': strategy,
            'confidence': 0.5
        }

    def _try_banter_engine(self, theme: str = "default") -> Optional[str]:
        """
        Try to get response from BanterEngine (lazy-loaded).

        Args:
            theme: Banter theme ('default', 'sarcastic', etc.)

        Returns:
            Banter response or None if BanterEngine unavailable
        """
        # Lazy-load BanterEngine on first use
        if self._banter_engine is None:
            try:
                from modules.ai_intelligence.banter_engine.src.banter_engine import BanterEngine
                self._banter_engine = BanterEngine()
                logger.info("[SKILL-1] BanterEngine loaded successfully")
            except Exception as e:
                logger.warning(f"[SKILL-1] BanterEngine not available: {e}")
                # Mark as failed to avoid retry on every execution
                self._banter_engine = False
                return None

        # If previous load failed, skip
        if self._banter_engine is False:
            return None

        # Try to get banter response
        try:
            response = self._banter_engine.get_random_banter(theme=theme)
            if response:
                return response
        except Exception as e:
            logger.warning(f"[SKILL-1] BanterEngine execution failed: {e}")

        return None
