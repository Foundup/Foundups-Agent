# Acoustic Lab - Implementation Walkthrough

## Code Structure and Flow

This document provides a detailed walkthrough of the Acoustic Lab implementation, following the architectural design through actual code paths. The implementation demonstrates educational acoustic processing while maintaining production-quality standards.

## Core Application Entry Point

### `web_app.py` - Flask Application

#### Application Initialization
```python
def create_app() -> Flask:
    app = Flask(__name__)

    # Initialize core components
    processor = get_acoustic_processor()

    # Register routes
    @app.route('/')
    def index():
        return render_template_string(get_html_template())

    @app.route('/upload', methods=['POST'])
    def upload_audio():
        # Processing logic (detailed below)

    @app.route('/health')
    def health_check():
        # Health monitoring

    return app
```

**Key Design Decisions**:
- **Singleton Pattern**: Single processor instance for efficiency
- **Route Separation**: Clear separation of UI and API endpoints
- **Error Handling**: Comprehensive exception management
- **Health Monitoring**: Production-ready status endpoints

## Input Processing Implementation

### File Upload Processing

#### Endpoint Logic Flow
```python
@app.route('/upload', methods=['POST'])
def upload_audio():
    try:
        # 1. IP Geofencing Check
        check_ip_geofencing(request.remote_addr)

        # 2. Input Type Detection
        if 'x_url' in request.form:
            # X video processing path
            file_data = process_x_video_url(request.form['x_url'])
            metadata['source'] = 'x_video'
        elif 'audio' in request.files:
            # File upload path
            file_data = request.files['audio'].read()
            metadata['source'] = 'direct_upload'
        else:
            raise BadRequest("Missing audio file or X URL")

        # 3. Audio Processing Pipeline
        results = processor.process_audio(file_data, metadata)

        # 4. Blockchain Proof Logging
        log_to_ethereum_testnet(results)

        return jsonify(results)

    except Exception as e:
        # Comprehensive error handling
        return jsonify({'error': str(e)}), appropriate_status_code
```

**Implementation Notes**:
- **Dual Input Support**: Single endpoint handles multiple input types
- **Early Validation**: Security checks before resource-intensive processing
- **Memory Management**: Direct BytesIO processing without temp files
- **Error Propagation**: Specific exceptions with educational messages

### X Video Processing Implementation

#### `process_x_video_url()` Function
```python
def process_x_video_url(x_url: str) -> bytes:
    try:
        # 1. yt-dlp Configuration
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'format': 'best[height<=720]',
            'outtmpl': '-',  # Memory output
        }

        # 2. Video Download to Temp File
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:
            temp_path = temp_video.name

        try:
            # Download video
            with yt_dlp.YoutubeDL(ydl_opts_temp) as ydl:
                ydl.download([x_url])

            # 3. Audio Extraction via ffmpeg
            ffmpeg_cmd = [
                'ffmpeg', '-i', temp_path,
                '-f', 'wav', '-t', '3',  # 3-second limit
                '-ac', '1', '-ar', '44100',  # Mono, 44.1kHz
                'pipe:1'
            ]

            process = subprocess.Popen(
                ffmpeg_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.DEVNULL
            )

            audio_data, _ = process.communicate(timeout=30)

            if len(audio_data) < 1000:
                raise BadRequest("No audio detected in video")

            return audio_data

        finally:
            # 4. Cleanup
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    except subprocess.TimeoutExpired:
        raise BadRequest("Audio extraction timeout")
```

**Technical Decisions**:
- **Temp File Necessity**: ffmpeg requires file input for reliable processing
- **Time Limits**: 3-second extraction prevents long-running operations
- **Quality Controls**: 720p limit balances quality vs bandwidth
- **Resource Cleanup**: Immediate temp file deletion

## Audio Processing Pipeline

### `AcousticProcessor` Class

#### Core Processing Flow
```python
class AcousticProcessor:
    def process_audio(self, audio_bytes: bytes, metadata: dict) -> dict:
        # 1. Load Audio
        audio, sr = librosa.load(io.BytesIO(audio_bytes), sr=44100)

        # 2. Peak Detection
        peaks = self._detect_peaks(audio, sr)

        if not peaks:
            raise AudioValidationError("No acoustic peaks detected")

        # 3. Window Extraction
        windows = [audio[max(0, peak-882):peak+882] for peak in peaks]

        # 4. MFCC Feature Extraction
        mfcc_features = []
        for window in windows:
            mfcc = librosa.feature.mfcc(
                y=window,
                sr=sr,
                n_mfcc=13,
                n_fft=2048,
                hop_length=512
            )
            mfcc_features.append(mfcc.mean(axis=1))

        # 5. Fingerprint Matching
        best_match, confidence = self.library.match_fingerprint(mfcc_features[0])

        # 6. Triangulation Calculation
        location = self.triangulation_engine.calculate_location(
            metadata.get('gps', {}),
            peaks[0] / sr  # Time offset
        )

        # 7. Results Compilation
        return {
            'location': location,
            'sound_type': best_match,
            'confidence': confidence,
            'triangulation_data': self.triangulation_engine.get_stats(),
            'ethereum_hash': self._generate_hash(results),
            'source': metadata.get('source', 'unknown')
        }
```

**Algorithm Details**:
- **Peak Detection**: Energy-based thresholding for synthetic tones
- **Windowing**: 0.2-second windows around detected peaks
- **MFCC Config**: Standard parameters for audio fingerprinting
- **Matching**: Cosine similarity against pre-computed fingerprints

### Audio Library Implementation

#### `AudioLibrary` Class
```python
class AudioLibrary:
    def __init__(self):
        self.tones = {
            'Tone A': self._generate_tone(1000, 'sine'),    # 1kHz sine
            'Tone B': self._generate_tone(1500, 'square'),  # 1.5kHz square
            'Tone C': self._generate_tone(2000, 'sawtooth') # 2kHz sawtooth
        }

        # Pre-compute MFCC fingerprints
        self.fingerprints = {}
        for name, audio in self.tones.items():
            mfcc = librosa.feature.mfcc(y=audio, sr=44100, n_mfcc=13)
            self.fingerprints[name] = mfcc.mean(axis=1)

    def match_fingerprint(self, query_features: np.ndarray) -> tuple[str, float]:
        best_match = None
        best_score = 0.0

        for name, stored_features in self.fingerprints.items():
            # Cosine similarity
            similarity = np.dot(query_features, stored_features) / (
                np.linalg.norm(query_features) * np.linalg.norm(stored_features)
            )

            if similarity > best_score:
                best_score = similarity
                best_match = name

        return best_match, min(best_score, 1.0)  # Cap at 1.0
```

**Educational Design**:
- **Simple Tones**: Three distinct waveforms for clear differentiation
- **Pre-computation**: Fingerprints calculated at startup for efficiency
- **Similarity Scoring**: Cosine distance for pattern matching
- **Confidence Bounds**: Normalized scoring between 0-1

### Triangulation Engine

#### `TriangulationEngine` Class
```python
class TriangulationEngine:
    def calculate_location(self, gps_data: dict, time_offset: float) -> list[float]:
        """
        Calculate sound source location using time-of-arrival triangulation.

        Args:
            gps_data: Dictionary with sensor GPS coordinates
            time_offset: Time delay from reference sensor

        Returns:
            [latitude, longitude] of sound source
        """
        # Simplified triangulation for educational purposes
        # In production, this would use proper geometric algorithms

        # Use provided GPS as center point
        base_lat = gps_data.get('latitude', 40.7649)
        base_lng = gps_data.get('longitude', -111.8421)

        # Add small random offset for educational variation
        # Real triangulation would solve for intersection points
        lat_offset = (time_offset * 343) / 111320  # Convert meters to degrees
        lng_offset = (time_offset * 343) / (111320 * math.cos(math.radians(base_lat)))

        return [
            base_lat + lat_offset * random.choice([-1, 1]),
            base_lng + lng_offset * random.choice([-1, 1])
        ]
```

**Educational Simplification**:
- **Demonstration Focus**: Simplified algorithm for learning concepts
- **Random Variation**: Shows effect of timing uncertainties
- **Geometric Concepts**: Illustrates triangulation principles
- **Extensible Design**: Ready for full geometric implementation

## Security Implementation

### IP Geofencing

#### `check_ip_geofencing()` Function
```python
def check_ip_geofencing(client_ip: str):
    try:
        # Free IP geolocation service
        response = requests.get(f'http://ip-api.com/json/{client_ip}', timeout=5)
        response.raise_for_status()

        data = response.json()

        if data.get('status') != 'success':
            raise IPGeofencingError("Unable to determine location")

        # Utah state check (educational restriction)
        region = data.get('region', '').upper()
        if region != 'UT':
            state_name = data.get('regionName', 'Unknown')
            raise IPGeofencingError(
                f"Educational access restricted to Utah state. "
                f"Detected location: {state_name} ({region})"
            )

    except requests.RequestException:
        # Graceful degradation - allow access if service unavailable
        print(f"Warning: IP geolocation check failed: {e}")
        print("Allowing access for educational purposes")
```

**Security Design**:
- **Geographic Restriction**: Educational access control
- **Service Resilience**: Graceful handling of API failures
- **Privacy Conscious**: No IP storage or tracking
- **Educational Context**: Utah restriction for demonstration

## Frontend Implementation

### HTML Interface

#### Educational UI Design
```html
<div class="container">
    <h1>Acoustic Lab</h1>
    <div class="description">
        <p>This tool teaches acoustic triangulation and audio fingerprinting.</p>
        <p>Upload synthetic audio to learn how math locates a sound source and identifies its type.</p>
        <p><strong>Educational Access:</strong> Restricted to Utah state for demonstration purposes.</p>
    </div>

    <!-- File Upload Zone -->
    <div class="upload-zone" id="uploadZone">
        <input type="file" id="audioFile" accept=".wav" />
        <label for="audioFile">
            <div>
                <h3>Drop WAV File Here</h3>
                <p>Or click to browse</p>
                <p><small>Synthetic audio only - educational use</small></p>
            </div>
        </label>
    </div>

    <!-- X URL Input (New Feature) -->
    <div class="x-url-section" style="text-align: center; margin: 20px 0;">
        <p>Or paste an X post URL with simulated audio to demonstrate analysis alongside direct uploads.</p>
        <input type="text" id="xurl" placeholder="https://x.com/..." />
        <button onclick="submitX()">Analyze</button>
    </div>
</div>
```

### JavaScript Implementation

#### File Upload Processing
```javascript
function processFile(file) {
    showLoading('Processing acoustic analysis...');

    // Create synthetic GPS metadata
    const metadata = {
        gps: {
            latitude: 40.7649 + (Math.random() - 0.5) * 0.01,
            longitude: -111.8421 + (Math.random() - 0.5) * 0.01
        },
        timestamp: new Date().toISOString()
    };

    // Form data submission
    const formData = new FormData();
    formData.append('audio', file);
    formData.append('metadata', JSON.stringify(metadata));

    fetch('/upload', { method: 'POST', body: formData })
        .then(response => response.json())
        .then(data => {
            if (data.error) {
                showError(data.error);
            } else {
                showResults(data);
            }
        })
        .catch(error => showError('Network error: ' + error.message));
}
```

#### X URL Processing
```javascript
function submitX() {
    const url = document.getElementById('xurl').value;

    // URL validation
    if (!url.includes('x.com') && !url.includes('twitter.com')) {
        showError('Invalid X link - must be an X.com or Twitter.com URL');
        return;
    }

    showLoading('Downloading and analyzing X video audio...');

    // Synthetic metadata for X videos
    const metadata = {
        gps: {
            latitude: 40.7649 + (Math.random() - 0.5) * 0.01,
            longitude: -111.8421 + (Math.random() - 0.5) * 0.01
        },
        timestamp: new Date().toISOString(),
        source: 'x_video'
    };

    // Form data with URL
    const formData = new FormData();
    formData.append('x_url', url);
    formData.append('metadata', JSON.stringify(metadata));

    fetch('/upload', { method: 'POST', body: formData })
        .then(response => response.json())
        .then(data => {
            if (data.error) {
                showError(data.error);
            } else {
                showResults(data);
            }
        })
        .catch(error => showError('Network error: ' + error.message));
}
```

## Ethereum Proof-of-Existence

### `EthereumLogger` Implementation

#### Blockchain Logging
```python
class EthereumLogger:
    def log_acoustic_analysis(self, results: dict) -> str:
        """
        Log SHA-256 hash of analysis results to Ethereum testnet.

        Educational demonstration - no real transactions.
        """
        # Create deterministic hash of results
        result_string = json.dumps(results, sort_keys=True, separators=(',', ':'))
        hash_value = hashlib.sha256(result_string.encode()).hexdigest()

        # Simulate Ethereum transaction (educational purposes)
        timestamp = int(time.time())
        simulated_tx = f"simulated_{hash_value[:32]}"

        # Educational logging
        print("ðŸŽ¯ Educational Proof-of-Existence")
        print(f"   ðŸ“Š Analysis Hash: {hash_value}")
        print(f"   â›“ï¸  Simulated TX: {simulated_tx}")
        print(f"   ðŸ“ Location: {results.get('location', 'Unknown')}")
        print(f"   ðŸ”Š Sound Type: {results.get('sound_type', 'Unknown')}")

        return simulated_tx
```

**Educational Value**:
- **Cryptographic Demonstration**: SHA-256 hash generation
- **Blockchain Concepts**: Proof-of-existence principles
- **Testnet Safety**: No real cryptocurrency transactions
- **Transparency**: Clear logging of the process

## Error Handling Patterns

### Exception Hierarchy
```python
class AcousticLabError(Exception):
    """Base exception for Acoustic Lab operations."""
    pass

class AudioValidationError(AcousticLabError):
    """Raised when audio file fails validation."""
    pass

class GPSValidationError(AcousticLabError):
    """Raised when GPS coordinates are invalid."""
    pass

class IPGeofencingError(AcousticLabError):
    """Raised when IP geofencing check fails."""
    pass

class XProcessingError(AcousticLabError):
    """Raised when X video processing fails."""
    pass
```

### Error Response Formatting
```python
def handle_processing_error(error: Exception) -> tuple[dict, int]:
    """Format error responses with appropriate HTTP status codes."""

    if isinstance(error, IPGeofencingError):
        return {'error': str(error)}, 403
    elif isinstance(error, (AudioValidationError, GPSValidationError)):
        return {'error': f'Validation failed: {str(error)}'}, 400
    elif isinstance(error, BadRequest):
        return {'error': str(error)}, 400
    else:
        app.logger.error(f"Unexpected error: {str(error)}")
        return {'error': 'Internal processing error'}, 500
```

## Performance Optimization

### Memory Management
```python
def process_audio_safe(audio_bytes: bytes) -> dict:
    """Process audio with explicit memory management."""

    # Use BytesIO for direct processing
    with io.BytesIO(audio_bytes) as audio_buffer:
        results = processor.process_audio_buffer(audio_buffer)

    # Explicit cleanup
    del audio_bytes

    return results
```

### Processing Timeouts
```python
def process_with_timeout(audio_data: bytes, timeout: int = 30) -> dict:
    """Process audio with timeout protection."""

    def _process():
        return processor.process_audio(audio_data)

    # Run in separate thread with timeout
    from concurrent.futures import ThreadPoolExecutor, TimeoutError

    with ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(_process)
        try:
            return future.result(timeout=timeout)
        except TimeoutError:
            raise AudioValidationError("Processing timeout - audio too complex")
```

## Testing Implementation

### Unit Test Structure
```python
# tests/test_acoustic_processor.py
def test_peak_detection():
    """Test synthetic tone peak detection."""
    processor = AcousticProcessor()

    # Generate test tone
    tone_audio = generate_synthetic_tone(1000, 'sine', duration=1.0)

    peaks = processor._detect_peaks(tone_audio, 44100)

    assert len(peaks) > 0, "Should detect peaks in synthetic tone"
    assert all(peak > 0 for peak in peaks), "Peak indices should be positive"

def test_fingerprint_matching():
    """Test audio fingerprint matching accuracy."""
    library = AudioLibrary()

    # Test known tone
    query_features = library.fingerprints['Tone A']

    match, confidence = library.match_fingerprint(query_features)

    assert match == 'Tone A', f"Expected Tone A, got {match}"
    assert confidence > 0.95, f"Confidence too low: {confidence}"
```

### Integration Test Example
```python
# tests/test_end_to_end.py
def test_file_upload_pipeline(client):
    """Test complete file upload to results pipeline."""

    # Create test WAV file
    test_audio = generate_test_wav_file()

    # Mock IP geofencing
    with patch('web_app.check_ip_geofencing'):
        response = client.post('/upload',
                             data={'audio': (test_audio, 'test.wav')},
                             content_type='multipart/form-data')

    assert response.status_code == 200

    data = json.loads(response.data)

    # Validate response structure
    assert 'location' in data
    assert 'sound_type' in data
    assert 'confidence' in data
    assert data['source'] == 'direct_upload'
```

## Deployment Configuration

### Gunicorn Production Setup
```python
# scripts/gunicorn.conf.py
workers = min(multiprocessing.cpu_count(), 4)
worker_class = 'sync'
max_requests = 500
timeout = 60
preload_app = True
```

### Nginx Reverse Proxy
```nginx
# scripts/nginx.conf
server {
    listen 443 ssl;
    server_name acoustic-lab.edu;

    # SSL configuration
    ssl_certificate /etc/letsencrypt/live/acoustic-lab.edu/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/acoustic-lab.edu/privkey.pem;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=acoustic_lab:10m rate=10r/s;
    limit_req zone=acoustic_lab burst=20 nodelay;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### Systemd Service
```ini
# scripts/acoustic-lab.service
[Service]
User=acoustic
WorkingDirectory=/var/www/acoustic-lab
ExecStart=/var/www/acoustic-lab/venv/bin/gunicorn --config scripts/gunicorn.conf.py
Restart=always
MemoryLimit=1G
CPUQuota=75%
```

## Implementation Quality Metrics

### Code Quality Standards
- **Type Hints**: Full Python typing throughout
- **Documentation**: Comprehensive docstrings
- **Error Handling**: Specific exception types
- **Testing**: 90%+ coverage target
- **Performance**: Sub-second response times
- **Security**: Defense-in-depth approach

### Educational Effectiveness
- **Transparency**: Clear algorithmic visibility
- **Safety**: Synthetic data restrictions
- **Scalability**: Production-ready architecture
- **Maintainability**: Modular, well-documented code
- **Extensibility**: Ready for Phase 2/3 features

---

**Acoustic Lab Implementation Walkthrough**
**Complete Code Flow and Technical Decisions**
**Educational Platform with Production Architecture**

