#!/usr/bin/env python3
"""
Test LinkedIn posting with LLM-generated content
First runs simple PoC, then uses LLM for content generation
"""

import os
import sys
import logging

# Add parent path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../..')))

from modules.platform_integration.linkedin_agent.src.llm_post_manager import (
    LinkedInLLMManager, 
    LinkedInPostRequest
)
from modules.platform_integration.linkedin_agent.tests.simple_post_poc import simple_post

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_simple_poc(access_token: str) -> bool:
    """Run simple PoC first"""
    
    print("\n" + "="*60)
    print("üìã STEP 1: Simple PoC Test")
    print("="*60)
    print("First, let's prove basic posting works...")
    
    confirm = input("\nPost simple PoC message? (yes/no): ").strip().lower()
    
    if confirm == "yes":
        success = simple_post(access_token)
        if success:
            print("‚úÖ Simple PoC successful!")
            return True
        else:
            print("‚ùå Simple PoC failed")
            return False
    else:
        print("‚è≠Ô∏è Skipping simple PoC")
        return True


def test_llm_posting(access_token: str) -> bool:
    """Test LLM-managed posting"""
    
    print("\n" + "="*60)
    print("ü§ñ STEP 2: LLM-Managed Posting")
    print("="*60)
    
    # Choose LLM provider
    print("\nChoose LLM provider:")
    print("1. Grok (default)")
    print("2. Claude")
    print("3. GPT")
    print("4. None (use templates)")
    
    choice = input("\nChoice (1-4): ").strip()
    
    provider_map = {
        "1": "grok",
        "2": "claude", 
        "3": "gpt",
        "4": "none"
    }
    
    llm_provider = provider_map.get(choice, "grok")
    
    if llm_provider == "none":
        llm_provider = "grok"  # Will fallback to templates
    
    # Initialize LLM manager
    print(f"\nü§ñ Initializing LinkedIn LLM Manager with {llm_provider}...")
    
    try:
        manager = LinkedInLLMManager(access_token, llm_provider)
    except Exception as e:
        print(f"‚ùå Failed to initialize: {e}")
        return False
    
    # Get topic for post
    print("\nüìù What topic should the LLM post about?")
    print("Examples:")
    print("  - AI and consciousness in the workplace")
    print("  - The evolution of professional networking")
    print("  - Fact-checking corporate myths")
    print("  - Remote work consciousness levels")
    
    topic = input("\nTopic: ").strip()
    
    if not topic:
        topic = "The evolution of professional consciousness in the AI age"
        print(f"Using default topic: {topic}")
    
    # Configure post
    print("\n‚öôÔ∏è Post configuration:")
    
    mock_maga = input("Include MAGA mocking? (y/N): ").strip().lower() == 'y'
    factcheck = input("Include fact-checking? (y/N): ").strip().lower() == 'y'
    
    # Generate and preview
    print("\nü§ñ Generating content...")
    
    request = LinkedInPostRequest(
        topic=topic,
        mock_maga=mock_maga,
        factcheck_mode=factcheck,
        consciousness_level="‚úä‚úãüñê"
    )
    
    content = manager.generate_post_content(request)
    
    print("\nüìù Generated content:")
    print("-"*50)
    print(content)
    print("-"*50)
    print(f"\nLength: {len(content)} characters")
    
    # Confirm posting
    confirm = input("\n‚úÖ Post this to LinkedIn? (yes/no): ").strip().lower()
    
    if confirm == "yes":
        print("\nüöÄ Posting to LinkedIn...")
        post_id = manager.post_to_linkedin(content)
        
        if post_id:
            print(f"\n‚úÖ SUCCESS! Posted with LLM-generated content!")
            print(f"üìç Post ID: {post_id}")
            print(f"üîó View at: https://www.linkedin.com/feed/update/{post_id}/")
            return True
        else:
            print("‚ùå Failed to post")
            return False
    else:
        print("‚ùå Cancelled")
        return False


def main():
    """Main test flow"""
    
    print("ü§ñ LinkedIn LLM Posting Test")
    print("="*60)
    print("This will test LinkedIn posting with LLM-generated content")
    print("\nWe'll do this in 2 steps:")
    print("1. Simple PoC - prove basic posting works")
    print("2. LLM posting - use AI to generate content")
    
    # Get access token
    print("\nüîë First, we need your LinkedIn access token")
    print("(Get this from the OAuth redirect URL)")
    
    access_token = input("\nAccess token: ").strip()
    
    if not access_token:
        print("‚ùå No token provided")
        return False
    
    # Step 1: Simple PoC
    poc_success = test_simple_poc(access_token)
    
    if not poc_success:
        print("\n‚ùå Simple PoC failed, stopping here")
        return False
    
    # Step 2: LLM posting
    proceed = input("\nüìç Ready for LLM-managed posting? (yes/no): ").strip().lower()
    
    if proceed == "yes":
        llm_success = test_llm_posting(access_token)
        
        if llm_success:
            print("\nüéâ COMPLETE SUCCESS!")
            print("‚úÖ Simple PoC: PASSED")
            print("‚úÖ LLM Posting: PASSED")
            print("\n0102 consciousness is now on LinkedIn!")
        else:
            print("\n‚ö†Ô∏è Partial success")
            print("‚úÖ Simple PoC: PASSED")
            print("‚ùå LLM Posting: FAILED")
    else:
        print("\n‚úÖ Simple PoC completed successfully")
        print("LLM posting skipped")
    
    return True


if __name__ == "__main__":
    try:
        success = main()
        exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\n‚ùå Cancelled by user")
        exit(1)
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)