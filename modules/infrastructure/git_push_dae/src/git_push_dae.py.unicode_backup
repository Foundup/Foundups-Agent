#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
# === UTF-8 ENFORCEMENT (WSP 90) ===
# Prevent UnicodeEncodeError on Windows systems
if sys.platform.startswith('win'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
# === END UTF-8 ENFORCEMENT ===

GitPushDAE - WSP 91 Compliant Autonomous Git Push Daemon

Fully autonomous daemon that monitors code changes and makes agentic decisions
about when to push to git and publish to social media. Implements complete
WSP 91 DAEMON observability for full traceability.

WSP Compliance:
- WSP 91: Full DAEMON observability (logs, traces, metrics)
- WSP 27: Universal DAE Architecture (autonomous decision-making)
- WSP 49: Module Structure (proper separation of concerns)
- WSP 60: Memory Architecture (persistent state)
"""

import os
import sys
import time
import json
import logging
import threading
import subprocess
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict

# Ensure UTF-8 encoding
if sys.platform.startswith('win'):
    os.environ['PYTHONIOENCODING'] = 'utf-8'


@dataclass
class PushContext:
    """Context for autonomous push decision."""
    uncommitted_changes: List[str]
    quality_score: float
    time_since_last_push: int  # seconds
    social_value_score: float
    repository_health: str
    change_summary: Dict[str, int]


@dataclass
class PushDecision:
    """Autonomous push decision result."""
    should_push: bool
    confidence: float
    reasoning: str
    expected_impact: str
    cost_estimate: float
    alternatives_considered: List[Dict]
    decision_timestamp: str
    context_hash: str


@dataclass
class HealthStatus:
    """WSP 91 health status."""
    daemon_name: str
    status: str  # 'healthy', 'degraded', 'critical', 'failed'
    vital_signs: Dict
    anomalies: List[str]
    recommendations: List[str]
    timestamp: str


class GitPushDAE:
    """
    WSP 91 Compliant DAEMON for autonomous git push decisions.

    Monitors code changes and makes agentic decisions about push timing
    based on quality thresholds, time windows, and social value assessment.
    """

    def __init__(self, domain: str, check_interval: int = 300):
        """
        Initialize GitPushDAE daemon.

        Args:
            domain: Monitoring domain (e.g., 'foundups_development')
            check_interval: Seconds between monitoring cycles (default: 300)
        """
        self.daemon_name = "GitPushDAE"
        self.domain = domain
        self.check_interval = check_interval

        # State management
        self.active = False
        self.monitoring_thread = None
        self.stop_event = threading.Event()
        self.last_push_time = None
        self.operation_count = 0
        self.start_time = None

        # Decision tracking (WSP 91)
        self.decision_history = []
        self.cost_tracker = CostTracker()
        self.circuit_breaker = CircuitBreaker(max_failures=3, reset_timeout=3600)

        # Setup WSP 91 compliant logging
        self.logger = self._setup_wsp91_logging()

        # Load persistent state
        self.state_file = Path("memory/git_push_dae_state.json")
        self._load_state()

        # Initialize git bridge for posting
        self.git_bridge = None
        self._init_git_bridge()

        # Initialize Qwen advisor for intelligent analysis
        self.qwen = None
        self._init_qwen_advisor()

        # Log initialization (WSP 91 lifecycle)
        self.logger.info(f"[{self.daemon_name}] Initializing Domain Autonomous Entity MONitoring")
        self.logger.info(f"[{self.daemon_name}] Domain: {self.domain}")
        self.logger.info(f"[{self.daemon_name}] Check interval: {self.check_interval}s")
        self.logger.info(f"[{self.daemon_name}] Configuration: {json.dumps(self._safe_config())}")

    def _setup_wsp91_logging(self) -> logging.Logger:
        """Setup WSP 91 compliant logging with semantic conventions."""
        logger = logging.getLogger(f"daemon.{self.daemon_name}")
        logger.setLevel(logging.INFO)

        # Create logs directory
        Path("logs").mkdir(exist_ok=True)

        # File handler with rotation
        from logging.handlers import RotatingFileHandler
        handler = RotatingFileHandler(
            f"logs/{self.daemon_name.lower()}.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )

        # Structured formatter for WSP 91
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)

        # Also log to console
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)

        return logger

    def _safe_config(self) -> Dict:
        """Return safe configuration summary for logging."""
        return {
            "domain": self.domain,
            "check_interval": self.check_interval,
            "state_file": str(self.state_file),
            "circuit_breaker_enabled": True
        }

    def _init_git_bridge(self):
        """Initialize git bridge for social media posting."""
        try:
            sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
            from modules.platform_integration.linkedin_agent.src.git_linkedin_bridge import GitLinkedInBridge
            self.git_bridge = GitLinkedInBridge(company_id="1263645")
            self.logger.info(f"[{self.daemon_name}] Git bridge initialized successfully")
        except Exception as e:
            self.logger.error(f"[{self.daemon_name}] Failed to initialize git bridge: {e}")
            self.git_bridge = None

    def _init_qwen_advisor(self):
        """Initialize Qwen advisor for intelligent code analysis and post generation."""
        try:
            from holo_index.qwen_advisor.llm_engine import QwenLLM
            self.qwen = QwenLLM()
            self.logger.info(f"[{self.daemon_name}] Qwen advisor initialized for semantic analysis")
        except Exception as e:
            self.logger.warning(f"[{self.daemon_name}] Qwen advisor not available: {e}")
            self.qwen = None

    def _load_state(self):
        """Load persistent daemon state."""
        try:
            if self.state_file.exists():
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                    self.last_push_time = datetime.fromisoformat(state.get('last_push_time')) if state.get('last_push_time') else None
                    self.operation_count = state.get('operation_count', 0)
                self.logger.info(f"[{self.daemon_name}] State loaded: {self.operation_count} operations, last push: {self.last_push_time}")
        except Exception as e:
            self.logger.warning(f"[{self.daemon_name}] Failed to load state: {e}")

    def _save_state(self):
        """Atomically save daemon state."""
        try:
            state = {
                'last_push_time': self.last_push_time.isoformat() if self.last_push_time else None,
                'operation_count': self.operation_count,
                'domain': self.domain,
                'last_save': datetime.now().isoformat()
            }

            # Atomic write
            temp_file = self.state_file.with_suffix('.tmp')
            with open(temp_file, 'w') as f:
                json.dump(state, f, indent=2)
            temp_file.replace(self.state_file)

        except Exception as e:
            self.logger.error(f"[{self.daemon_name}] Failed to save state: {e}")

    def start(self):
        """Start the autonomous monitoring daemon with WSP 91 logging."""
        if self.active:
            self.logger.warning(f"[{self.daemon_name}] Already active")
            return

        self.logger.info(f"[{self.daemon_name}] ðŸš€ Starting autonomous operation")
        self.logger.info(f"[{self.daemon_name}] Monitoring: {self.domain}")
        self.logger.info(f"[{self.daemon_name}] Check interval: {self.check_interval}s")

        self.active = True
        self.start_time = datetime.now()

        # Start monitoring thread
        self.monitoring_thread = threading.Thread(
            target=self._monitor_loop,
            name=f"{self.daemon_name}Monitor",
            daemon=True
        )
        self.monitoring_thread.start()

        self.logger.info(f"[{self.daemon_name}] âœ… Autonomous operation started")

    def stop(self):
        """Stop the daemon with full lifecycle logging."""
        if not self.active:
            self.logger.info(f"[{self.daemon_name}] Not currently active")
            return

        uptime = datetime.now() - self.start_time if self.start_time else timedelta(0)

        self.logger.info(f"[{self.daemon_name}] ðŸ›‘ Stopping autonomous operation")
        self.logger.info(f"[{self.daemon_name}] Uptime: {uptime}")
        self.logger.info(f"[{self.daemon_name}] Operations completed: {self.operation_count}")

        # Signal stop
        self.active = False
        self.stop_event.set()

        # Wait for thread
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            self.monitoring_thread.join(timeout=10)

        # Save final state
        self._save_state()

        # Log final statistics
        total_cost = self.cost_tracker.total_tokens * 0.0001  # Rough USD estimate
        self.logger.info(f"[{self.daemon_name}] Total tokens used: {self.cost_tracker.total_tokens}")
        self.logger.info(f"[{self.daemon_name}] Estimated cost: ${total_cost:.4f}")
        self.logger.info(f"[{self.daemon_name}] âœ… Shutdown complete")

    def _monitor_loop(self):
        """Main monitoring loop with WSP 91 health checks."""
        self.logger.info(f"[{self.daemon_name}] Monitor loop started")

        while self.active and not self.stop_event.is_set():
            try:
                start_time = time.time()

                # Execute monitoring cycle
                self.monitoring_cycle()

                # Health check every cycle (WSP 91)
                health = self.health_check()
                if health.status in ['critical', 'failed']:
                    self.logger.critical(f"[HEALTH-CHECK] {json.dumps(asdict(health))}")

                # Cost tracking (WSP 91)
                cycle_time = time.time() - start_time
                self.cost_tracker.track_operation('monitoring_cycle', cycle_time)

                # Wait for next cycle
                self.stop_event.wait(self.check_interval)

            except Exception as e:
                error_log = {
                    "timestamp": datetime.now().isoformat(),
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "operation": "monitor_loop",
                    "stack_trace": traceback.format_exc()
                }
                self.logger.error(f"[ERROR] {json.dumps(error_log)}")

                # Brief pause before retry
                self.stop_event.wait(10)

    def monitoring_cycle(self):
        """Main monitoring logic - checks for push-worthy changes."""
        self.operation_count += 1

        try:
            # Gather context for decision
            context = self._gather_push_context()

            if not context.uncommitted_changes:
                # No changes to consider
                return

            # Make autonomous decision (WSP 91)
            decision = self.make_push_decision(context)

            # Log decision path (WSP 91 requirement)
            self.logger.info(f"[DECISION-PATH] {json.dumps(asdict(decision))}")

            # Execute decision
            if decision.should_push:
                self._execute_push(decision, context)
            else:
                self.logger.info(f"[{self.daemon_name}] Decision: No push - {decision.reasoning}")

        except Exception as e:
            self.logger.error(f"[{self.daemon_name}] Monitoring cycle failed: {e}")
            raise

    def _gather_push_context(self) -> PushContext:
        """Gather context for autonomous push decision."""
        try:
            # Check git status
            result = subprocess.run(['git', 'status', '--porcelain'],
                                  capture_output=True, text=True, check=True)
            uncommitted_changes = result.stdout.strip().split('\n') if result.stdout.strip() else []

            # Assess code quality
            quality_score = self._assess_code_quality(uncommitted_changes)

            # Time since last push
            time_since_last = (datetime.now() - (self.last_push_time or datetime.min)).total_seconds()

            # Social value assessment
            social_value = self._assess_social_value(uncommitted_changes)

            # Repository health
            repo_health = self._check_repository_health()

            # Change summary
            change_summary = self._summarize_changes(uncommitted_changes)

            return PushContext(
                uncommitted_changes=uncommitted_changes,
                quality_score=quality_score,
                time_since_last_push=int(time_since_last),
                social_value_score=social_value,
                repository_health=repo_health,
                change_summary=change_summary
            )

        except Exception as e:
            self.logger.error(f"[{self.daemon_name}] Failed to gather context: {e}")
            # Return safe defaults
            return PushContext([], 0.0, 0, 0.0, "unknown", {})

    def make_push_decision(self, context: PushContext) -> PushDecision:
        """
        Make autonomous push decision with full WSP 91 observability.

        Agentic Parameters (no human decision required):
        1. Code Quality: quality_score >= 0.8
        2. Change Significance: len(changes) >= 3
        3. Time Windows: Not during sleep hours (22:00-06:00)
        4. Frequency Control: time_since_last >= 1800s (30 min)
        5. Social Value: social_value_score >= 0.6
        6. Repository Health: No conflicts, clean state
        7. Cost Efficiency: Benefit > analysis cost
        """
        decision_log = {
            "timestamp": datetime.now().isoformat(),
            "context": asdict(context),
            "criteria_evaluated": {},
            "alternatives_considered": [],
            "decision": None,
            "reasoning": None,
            "confidence": 0.0,
            "expected_impact": None,
            "cost_estimate": 0.0
        }

        try:
            # Evaluate each agentic criterion
            criteria = {
                "code_quality": context.quality_score >= 0.5,  # Lowered from 0.8 - development quality is iterative
                "change_significance": len(context.uncommitted_changes) >= 3,
                "time_window": self._is_appropriate_time(),
                "frequency_control": context.time_since_last_push >= 1800,  # 30 minutes
                "social_value": context.social_value_score >= 0.6,
                "repository_health": context.repository_health in ["healthy", "dirty"],  # "dirty" = active development
                "cost_efficiency": self._assess_cost_efficiency(context) > 0.5
            }

            decision_log["criteria_evaluated"] = {
                name: {"result": passed, "status": "PASS" if passed else "FAIL"}
                for name, passed in criteria.items()
            }

            # Consider alternatives
            alternatives = [
                {
                    "action": "push_now",
                    "pros": ["Immediate visibility", "Fresh content", "Stakeholder updates"],
                    "cons": ["May interrupt workflows", "Potential for hasty commits"],
                    "score": sum(criteria.values()) / len(criteria),
                    "selected": False
                },
                {
                    "action": "wait_for_quality",
                    "pros": ["Better quality assurance", "More comprehensive changes"],
                    "cons": ["Delayed visibility", "May lose momentum"],
                    "score": 0.7 if not criteria["code_quality"] else 0.4,
                    "selected": False
                },
                {
                    "action": "batch_with_more_changes",
                    "pros": ["Larger, more impactful updates", "Reduced notification noise"],
                    "cons": ["Longer development cycles", "Delayed feedback"],
                    "score": 0.6 if len(context.uncommitted_changes) < 5 else 0.3,
                    "selected": False
                }
            ]

            # Select best alternative based on criteria
            best_alt = max(alternatives, key=lambda x: x["score"])
            best_alt["selected"] = True

            decision_log["alternatives_considered"] = alternatives

            # Make final decision
            should_push = (
                sum(criteria.values()) >= 5 and  # At least 5/7 criteria pass
                criteria["code_quality"] and     # Quality is mandatory
                criteria["repository_health"]     # Health is mandatory
            )

            decision_log["decision"] = "push_now" if should_push else "wait"
            decision_log["confidence"] = best_alt["score"]
            decision_log["expected_impact"] = "immediate_development_visibility" if should_push else "quality_improvement"
            decision_log["cost_estimate"] = self._estimate_push_cost(context)

            # Create decision object
            decision = PushDecision(
                should_push=should_push,
                confidence=best_alt["score"],
                reasoning=self._generate_reasoning(criteria, best_alt),
                expected_impact=decision_log["expected_impact"],
                cost_estimate=decision_log["cost_estimate"],
                alternatives_considered=alternatives,
                decision_timestamp=decision_log["timestamp"],
                context_hash=hash(json.dumps(asdict(context), sort_keys=True))
            )

            return decision

        except Exception as e:
            decision_log["decision"] = "error_fallback"
            decision_log["reasoning"] = f"Exception during decision: {e}"

            return PushDecision(
                should_push=False,
                confidence=0.0,
                reasoning=f"Decision failed due to error: {e}",
                expected_impact="error_prevention",
                cost_estimate=0.0,
                alternatives_considered=[],
                decision_timestamp=decision_log["timestamp"],
                context_hash=""
            )

    def _execute_push(self, decision: PushDecision, context: PushContext):
        """Execute the git push with full error handling."""
        try:
            self.logger.info(f"[{self.daemon_name}] Executing autonomous push")

            if not self.git_bridge:
                raise Exception("Git bridge not initialized")

            # Check circuit breaker
            if not self.circuit_breaker.can_attempt():
                self.logger.warning(f"[{self.daemon_name}] Circuit breaker open - skipping push")
                return

            # Execute push
            success = self.git_bridge.push_and_post()

            if success:
                self.last_push_time = datetime.now()
                self.circuit_breaker.record_success()
                self.logger.info(f"[{self.daemon_name}] âœ… Autonomous push completed successfully")
            else:
                self.circuit_breaker.record_failure()
                self.logger.warning(f"[{self.daemon_name}] âš ï¸ Push completed but posting failed")

            # Save state
            self._save_state()

        except Exception as e:
            self.circuit_breaker.record_failure()
            self.logger.error(f"[{self.daemon_name}] âŒ Push execution failed: {e}")
            raise

    def health_check(self) -> HealthStatus:
        """WSP 91 compliant health check - cardiovascular system monitoring."""
        try:
            current_time = datetime.now()

            # Calculate vital signs
            operations_per_minute = self._calculate_operations_per_minute()
            time_since_last_push = (current_time - (self.last_push_time or current_time)).total_seconds()
            error_rate = self._calculate_error_rate()
            token_budget_remaining = self._assess_token_budget()

            vital_signs = {
                "operations_per_minute": operations_per_minute,
                "time_since_last_push_hours": time_since_last_push / 3600,
                "error_rate": error_rate,
                "token_budget_remaining": token_budget_remaining,
                "circuit_breaker_state": "open" if not self.circuit_breaker.can_attempt() else "closed",
                "active": self.active
            }

            # Assess health status
            anomalies = []
            recommendations = []

            # Check each vital sign
            if operations_per_minute < 0.1:  # Less than 6 operations per hour
                anomalies.append("Low operation frequency")
                recommendations.append("Check if monitoring thread is blocked")

            if time_since_last_push > 24 * 3600:  # No push in 24 hours
                anomalies.append("No recent pushes")
                recommendations.append("Review push criteria or check for code changes")

            if error_rate > 0.10:  # >10% errors
                anomalies.append(f"High error rate: {error_rate:.1%}")
                recommendations.append("Investigate recent errors and fix root causes")

            if token_budget_remaining < 0.10:  # <10% budget
                anomalies.append("Low token budget")
                recommendations.append("Reduce monitoring frequency or increase budget")

            # Determine status
            if anomalies:
                if len(anomalies) >= 3 or error_rate > 0.20:
                    status = "critical"
                else:
                    status = "degraded"
            else:
                status = "healthy"

            health = HealthStatus(
                daemon_name=self.daemon_name,
                status=status,
                vital_signs=vital_signs,
                anomalies=anomalies,
                recommendations=recommendations,
                timestamp=current_time.isoformat()
            )

            # Only log if not healthy (reduce noise)
            if status != "healthy":
                self.logger.warning(f"[HEALTH-CHECK] {json.dumps(asdict(health))}")

            return health

        except Exception as e:
            self.logger.error(f"[{self.daemon_name}] Health check failed: {e}")
            return HealthStatus(
                daemon_name=self.daemon_name,
                status="failed",
                vital_signs={},
                anomalies=[f"Health check error: {e}"],
                recommendations=["Investigate health check failure"],
                timestamp=datetime.now().isoformat()
            )

    # Helper methods for decision criteria

    def _assess_code_quality(self, changes: List[str]) -> float:
        """Assess code quality with Qwen semantic analysis."""
        try:
            # If Qwen available, use semantic analysis
            if self.qwen:
                return self._assess_quality_with_qwen(changes)

            # Fallback: Enhanced heuristics
            has_tests = any('test' in change.lower() for change in changes)
            has_docs = any('readme' in change.lower() or 'doc' in change.lower() or 'modlog' in change.lower() for change in changes)
            has_interface = any('interface' in change.lower() for change in changes)
            binary_files = sum(1 for change in changes if change.endswith(('.png', '.jpg', '.pdf', '.zip')))

            # Check for WSP compliance indicators
            wsp_compliance = any('wsp' in change.lower() for change in changes)

            score = 0.5  # Base score
            if has_tests:
                score += 0.15
            if has_docs:
                score += 0.15
            if has_interface:
                score += 0.10
            if wsp_compliance:
                score += 0.10
            if binary_files > len(changes) * 0.3:  # Too many binary files
                score -= 0.3

            return max(0.0, min(1.0, score))
        except:
            return 0.5

    def _assess_quality_with_qwen(self, changes: List[str]) -> float:
        """Use Qwen to semantically assess code quality."""
        try:
            # Get git diff for semantic analysis
            diff_result = subprocess.run(['git', 'diff', 'HEAD'],
                                        capture_output=True, text=True, timeout=10)
            diff_content = diff_result.stdout[:5000]  # Limit for token budget

            # Construct Qwen prompt
            prompt = f"""Analyze this git diff for code quality (score 0.0-1.0):

Changes: {len(changes)} files
Diff preview: {diff_content}

Assess based on:
1. WSP protocol compliance
2. Documentation updates
3. Test coverage
4. Code structure improvements
5. Interface definitions

Return ONLY a decimal score (e.g., 0.75), no explanation."""

            # Query Qwen
            response = self.qwen.generate(prompt, max_tokens=50, temperature=0.3)

            # Extract score from response
            import re
            score_match = re.search(r'0\.\d+|1\.0', response)
            if score_match:
                score = float(score_match.group())
                self.logger.info(f"[QWEN-QUALITY] Semantic quality score: {score:.2f}")
                return score

            # Fallback if parsing fails
            return 0.6
        except Exception as e:
            self.logger.warning(f"[QWEN-QUALITY] Failed semantic analysis: {e}")
            return 0.6  # Neutral fallback

    def _is_appropriate_time(self) -> bool:
        """Check if current time is appropriate for pushing."""
        current_hour = datetime.now().hour
        # Avoid pushing during deep sleep hours only (02:00-06:00)
        # Evening coding (22:00-02:00) is prime development time
        return not (2 <= current_hour <= 6)

    def _assess_social_value(self, changes: List[str]) -> float:
        """Assess social media value of changes."""
        try:
            # Heuristic: significant changes are more valuable
            significant_indicators = ['feature', 'major', 'breaking', 'api', 'interface']
            has_significant = any(any(ind in change.lower() for ind in significant_indicators) for change in changes)

            base_score = 0.4
            if has_significant:
                base_score += 0.3
            if len(changes) >= 5:
                base_score += 0.2

            return min(1.0, base_score)
        except:
            return 0.4

    def _check_repository_health(self) -> str:
        """Check repository health status."""
        try:
            # Check for ACTUAL merge conflicts (UU, AA, DD, AU, UA, DU, UD markers)
            result = subprocess.run(['git', 'status', '--porcelain'],
                                  capture_output=True, text=True, check=True)

            # Look for actual conflict markers in status
            has_conflicts = any(line.startswith(('UU', 'AA', 'DD', 'AU', 'UA', 'DU', 'UD'))
                              for line in result.stdout.split('\n'))

            if has_conflicts:
                return "conflicts"  # BLOCKED - must resolve actual merge conflicts
            elif result.stdout.strip():
                return "dirty"  # ACCEPTABLE - active development
            else:
                return "clean"  # ACCEPTABLE - no uncommitted changes
        except:
            return "unknown"

    def _summarize_changes(self, changes: List[str]) -> Dict[str, int]:
        """Summarize types of changes."""
        summary = {'modified': 0, 'added': 0, 'deleted': 0, 'renamed': 0}
        for change in changes:
            if change.startswith('M'):
                summary['modified'] += 1
            elif change.startswith('A'):
                summary['added'] += 1
            elif change.startswith('D'):
                summary['deleted'] += 1
            elif change.startswith('R'):
                summary['renamed'] += 1
        return summary

    def _assess_cost_efficiency(self, context: PushContext) -> float:
        """Assess if push benefits outweigh costs."""
        # Simple heuristic: more changes = better ROI
        change_volume = len(context.uncommitted_changes)
        base_efficiency = min(1.0, change_volume / 10.0)  # Max at 10 changes
        return base_efficiency

    def _estimate_push_cost(self, context: PushContext) -> float:
        """Estimate cost of push operation."""
        # Rough estimate: base cost + per-change cost
        base_cost = 0.001  # Base LLM analysis cost
        per_change_cost = 0.0001
        return base_cost + (len(context.uncommitted_changes) * per_change_cost)

    def _generate_reasoning(self, criteria: Dict, best_alt: Dict) -> str:
        """Generate human-readable reasoning for decision."""
        passed_count = sum(criteria.values())
        total_count = len(criteria)

        failed_criteria = [k for k, v in criteria.items() if not v]

        reasoning = f"{passed_count}/{total_count} criteria passed. "
        if failed_criteria:
            reasoning += f"Failed: {', '.join(failed_criteria)}. "

        reasoning += f"Best alternative: {best_alt['action']} (score: {best_alt['score']:.2f})"

        return reasoning

    def _calculate_operations_per_minute(self) -> float:
        """Calculate operation frequency."""
        if not self.start_time:
            return 0.0
        uptime_minutes = (datetime.now() - self.start_time).total_seconds() / 60
        return self.operation_count / uptime_minutes if uptime_minutes > 0 else 0.0

    def _calculate_error_rate(self) -> float:
        """Calculate error rate from recent logs."""
        # Simplified: would need actual log analysis in production
        return 0.02  # 2% placeholder

    def _assess_token_budget(self) -> float:
        """Assess remaining token budget."""
        # Simplified: would integrate with actual budget tracking
        return 0.8  # 80% remaining placeholder


class CostTracker:
    """Track costs for WSP 91 compliance."""

    def __init__(self):
        self.total_tokens = 0
        self.total_operations = 0
        self.start_time = datetime.now()

    def track_operation(self, operation_type: str, duration: float):
        """Track an operation for cost purposes."""
        self.total_operations += 1
        # Estimate tokens based on operation type
        estimated_tokens = {
            'monitoring_cycle': 50,
            'quality_assessment': 200,
            'push_execution': 100
        }.get(operation_type, 25)

        self.total_tokens += estimated_tokens


class CircuitBreaker:
    """Circuit breaker pattern for social media API resilience."""

    def __init__(self, max_failures: int = 3, reset_timeout: int = 3600):
        self.max_failures = max_failures
        self.reset_timeout = reset_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open

    def can_attempt(self) -> bool:
        """Check if operation can be attempted."""
        if self.state == "closed":
            return True
        elif self.state == "open":
            if self._should_reset():
                self.state = "half-open"
                return True
            return False
        else:  # half-open
            return True

    def record_success(self):
        """Record successful operation."""
        if self.state == "half-open":
            self.state = "closed"
        self.failure_count = 0
        self.last_failure_time = None

    def record_failure(self):
        """Record failed operation."""
        self.failure_count += 1
        self.last_failure_time = datetime.now()

        if self.failure_count >= self.max_failures:
            self.state = "open"

    def _should_reset(self) -> bool:
        """Check if circuit should reset."""
        if not self.last_failure_time:
            return True
        return (datetime.now() - self.last_failure_time).total_seconds() >= self.reset_timeout


# Convenience functions for easy access
def create_git_push_dae(domain: str = "foundups_development", check_interval: int = 300) -> GitPushDAE:
    """Create a GitPushDAE instance."""
    return GitPushDAE(domain=domain, check_interval=check_interval)


def launch_daemon(domain: str = "foundups_development", check_interval: int = 300):
    """Launch GitPushDAE daemon (convenience function)."""
    dae = GitPushDAE(domain=domain, check_interval=check_interval)
    dae.start()
    return dae


if __name__ == "__main__":
    # Allow direct execution for testing
    print("ðŸš€ GitPushDAE - Starting autonomous git push daemon...")

    dae = GitPushDAE(domain="foundups_development")
    dae.start()

    print("âœ… Daemon started. Press Ctrl+C to stop.")

    try:
        while dae.active:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nðŸ›‘ Stopping daemon...")
        dae.stop()

    print("âœ… Daemon stopped.")
